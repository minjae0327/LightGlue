{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2 \n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from vidstab import VidStab\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import load_image, rbd\n",
    "import CSRansac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n",
    "#matcher.compile(mode='reduce-overhead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (640, 480))  # 필요한 경우 이미지 크기 조정\n",
    "    image = K.image_to_tensor(image, False).float() / 255.0\n",
    "    image = image.to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lightglue(img0, img1):\n",
    "    img0 = load_image(img0)\n",
    "    img1 = load_image(img1)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    \n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "    \n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "        \n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilizer = VidStab()\n",
    "\n",
    "def matching_keypoints(target_img, video_img, stabilizing=False):\n",
    "    # 이미지를 불러옴\n",
    "    img0 = load_image(target_img, grayscale=True)\n",
    "    if stabilizing == True:\n",
    "        img1 = cv2.imread(video_img)\n",
    "        img1 = stabilizer.stabilize_frame(img1)\n",
    "        img1 = load_image(img1, grayscale=True)\n",
    "    else:\n",
    "        img1 = load_image(video_img , grayscale=True)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "\n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "\n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "\n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cracked_image = \"CrackedImage.PNG\"\n",
    "video = \"Roboinspect.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m img1 \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# LightGlue\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m results_lightglue \u001b[38;5;241m=\u001b[39m \u001b[43mmatching_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstabilizing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m target_keypoint \u001b[38;5;241m=\u001b[39m results_lightglue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     23\u001b[0m frame_keypoint \u001b[38;5;241m=\u001b[39m results_lightglue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mmatching_keypoints\u001b[1;34m(target_img, video_img, stabilizing)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatching_keypoints\u001b[39m(target_img, video_img, stabilizing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 이미지를 불러옴\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     img0 \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stabilizing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         img1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(video_img)\n",
      "File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\utils.py:83\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(image, resize, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     image \u001b[38;5;241m=\u001b[39m Path(image)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, Path):\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_image_from_path(image, resize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy_image_to_torch(image)\n",
      "File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\utils.py:73\u001b[0m, in \u001b[0;36mload_image_from_path\u001b[1;34m(path, resize, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_from_path\u001b[39m(path: Path, resize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 73\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         image, _ \u001b[38;5;241m=\u001b[39m resize_image(image, resize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\utils.py:93\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, grayscale)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo image at path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m mode \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE \u001b[38;5;28;01mif\u001b[39;00m grayscale \u001b[38;5;28;01melse\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR\n\u001b[1;32m---> 93\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not read image at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 크랙 이미지를 통해 크랙을 탐지함\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "x, y = 1408 / 2, 792 / 2\n",
    "\n",
    "# 동영상 저장 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (640, 360))  # 파일명, 프레임 속도, 해상도\n",
    "\n",
    "img0 = cracked_image\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    img1 = frame\n",
    "    \n",
    "    # LightGlue\n",
    "    results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n",
    "    target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n",
    "    frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n",
    "\n",
    "    # CSRansac으로 호모그래피 계산 및 mask 확인\n",
    "    homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n",
    "    \n",
    "    # mask가 0.7 이상일 때 화면 중앙에 빨간 점 그리기\n",
    "    if np.mean(mask) >= 0.8:\n",
    "        pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "        #cv2.circle(frame, (int(pts[0]), int(pts[1])), 10, (0, 0, 255), -1)  # 빨간 점 그리기\n",
    "        cv2.rectangle(frame, (int(pts[0])-100, int(pts[1])-100), (int(pts[0])+100, int(pts[1])+100), (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "    # 프레임을 동영상 파일로 저장\n",
    "    out.write(frame)\n",
    "    \n",
    "    # 프레임 출력\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:  # ESC 키를 누르면 종료\n",
    "        break\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "out.release()  # 저장 파일 닫기\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
