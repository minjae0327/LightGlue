{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2 \n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from vidstab import VidStab\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import load_image, rbd\n",
    "import CSRansac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n",
    "#matcher.compile(mode='reduce-overhead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (640, 360))  # 필요한 경우 이미지 크기 조정\n",
    "    image = K.image_to_tensor(image, False).float() / 255.0\n",
    "    image = image.to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lightglue(img0, img1):\n",
    "    img0 = load_image(img0)\n",
    "    img1 = load_image(img1)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    \n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "    \n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "        \n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilizer = VidStab()\n",
    "\n",
    "def matching_keypoints(target_img, video_img, stabilizing=False):\n",
    "    # 이미지를 불러옴\n",
    "    img0 = load_image(target_img, grayscale=True)\n",
    "    if stabilizing == True:\n",
    "        img1 = cv2.imread(video_img)\n",
    "        img1 = stabilizer.stabilize_frame(img1)\n",
    "        img1 = load_image(img1, grayscale=True)\n",
    "    else:\n",
    "        img1 = load_image(video_img , grayscale=True)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "\n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "\n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "\n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cracked_image = \"CrackedImage.PNG\"\n",
    "video = \"Roboinspect.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크랙 이미지를 통해 크랙을 탐지함\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "x, y = 1408 / 2, 792 / 2\n",
    "\n",
    "# 동영상 저장 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (640, 360))  # 파일명, 프레임 속도, 해상도\n",
    "\n",
    "img0 = cracked_image\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    img1 = frame\n",
    "    \n",
    "    # LightGlue\n",
    "    results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n",
    "    target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n",
    "    frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n",
    "\n",
    "    # CSRansac으로 호모그래피 계산 및 mask 확인\n",
    "    homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n",
    "    \n",
    "    # mask가 0.7 이상일 때 화면 중앙에 빨간 점 그리기\n",
    "    if np.mean(mask) >= 0.8:\n",
    "        pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "        cv2.circle(frame, (int(pts[0]), int(pts[1])), 10, (0, 0, 255), -1)  # 빨간 점 그리기\n",
    "    \n",
    "    # 프레임을 동영상 파일로 저장\n",
    "    out.write(frame)\n",
    "    \n",
    "    # 프레임 출력\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:  # ESC 키를 누르면 종료\n",
    "        break\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "out.release()  # 저장 파일 닫기\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
