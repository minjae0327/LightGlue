{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightglue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mgetcwd()))))\n\u001b[0;32m     16\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightglue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightGlue, SuperPoint\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightglue\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_image, rbd\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mCSRansac\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightglue'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2 \n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from vidstab import VidStab\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import load_image, rbd\n",
    "import CSRansac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n",
    "#matcher.compile(mode='reduce-overhead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lightglue(img0, img1):\n",
    "    img0 = load_image(img0)\n",
    "    img1 = load_image(img1)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    \n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "    \n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "        \n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (640, 480))  # 필요한 경우 이미지 크기 조정\n",
    "    image = K.image_to_tensor(image, False).float() / 255.0\n",
    "    image = image.to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilizer = VidStab()\n",
    "\n",
    "def matching_keypoints(target_img, video_img, stabilizing=False):\n",
    "    # 이미지를 불러옴\n",
    "    img0 = load_image(target_img, grayscale=True)\n",
    "    if stabilizing == True:\n",
    "        img1 = cv2.imread(video_img)\n",
    "        img1 = stabilizer.stabilize_frame(img1)\n",
    "        img1 = load_image(img1, grayscale=True)\n",
    "    else:\n",
    "        img1 = load_image(video_img , grayscale=True)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "\n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "\n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "\n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cracked_image = \"CrackedImage.PNG\"\n",
    "video = \"Roboinspect.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크랙 이미지를 통해 크랙을 탐지함\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "img0 = cracked_image\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    img1 = frame\n",
    "    \n",
    "    # LightGlue\n",
    "    results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n",
    "    target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n",
    "    frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n",
    "\n",
    "    homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n",
    "    if mask >= 0.7:\n",
    "        print(\"Crack Detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
