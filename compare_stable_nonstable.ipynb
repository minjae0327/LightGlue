{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from vidstab import VidStab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightglue import viz2d\n",
    "from lightglue import LightGlue, SuperPoint, DISK\n",
    "from lightglue.utils import load_image, rbd, load_image_from_path\n",
    "import CSRansac\n",
    "\n",
    "from vidstab import VidStab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n",
    "#matcher.compile(mode='reduce-overhead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_datasets = \"datasets\"\n",
    "\n",
    "lables = os.path.join(aircraft_datasets + \"/label\")\n",
    "video_dir = os.path.join(aircraft_datasets, \"video\")\n",
    "target_image_dir = os.path.join(aircraft_datasets, \"target_image\")\n",
    "# 비디오 안정화 객체 생성\n",
    "stabilizer = VidStab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "disappear_error = 0\n",
    "misannotate_error = 0\n",
    "pixel_error = 0\n",
    "\n",
    "missing_inlier = 0\n",
    "failed_inliers = 0\n",
    "\n",
    "x = 637 // 2\n",
    "y = 367 // 2\n",
    "\n",
    "# 저장할 동영상 파일명 및 코덱 설정\n",
    "output_video_path = 'lightglue_unstable_result.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_fps = 30.0  # 저장할 동영상의 프레임 속도\n",
    "\n",
    "cap = cv2.VideoCapture('demo_video_resized.mp4')\n",
    "image0 = load_image(\"img0.png\", grayscale=True)\n",
    "\n",
    "# 저장할 동영상의 너비와 높이 설정\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, output_video_fps, (frame_width, frame_height))\n",
    "\n",
    "count = 0\n",
    "\n",
    "# 각 프레임을 VideoWriter에 쓰기\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임에 작업 수행\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        continue\n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    image1 = load_image(frame, grayscale=True)\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    \n",
    "    feats0, feats1, matches01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "    \n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "    \n",
    "    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n",
    "    if mask < 0.3:\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        failed_inliers += 1\n",
    "        continue\n",
    "    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "    #image0 = image1\n",
    "    \n",
    "    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # 동영상 파일에 프레임 추가\n",
    "    out.write(frame)\n",
    "\n",
    "    # 화면에 표시\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    float_x = x / 640\n",
    "    float_y = y / 480\n",
    "    _x = int(projected_pts[0]) / 640\n",
    "    _y = int(projected_pts[1]) / 480\n",
    "    \n",
    "    if _x < 0 or _x > 1 or _y < 0 or _y > 1:\n",
    "        disappear_error += 1\n",
    "        \n",
    "    distance = np.sqrt((_x - float_x) ** 2 + (_y - float_y) ** 2)\n",
    "    if distance > 0.1:\n",
    "        misannotate_error += 1\n",
    "        \n",
    "    if distance > pixel_error:\n",
    "        pixel_error = distance\n",
    "    \n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# VideoWriter 객체 해제\n",
    "out.release()\n",
    "\n",
    "# VideoCapture 객체 해제\n",
    "cap.release()\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappear_error: 0\n",
      "misannotate_error: 0\n",
      "pixel_error: 0.06406250000000002\n",
      "missing_inlier: 0\n",
      "failed_inliers: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"disappear_error:\", disappear_error)\n",
    "print(\"misannotate_error:\", misannotate_error)\n",
    "print(\"pixel_error:\", pixel_error)  \n",
    "print(\"missing_inlier:\", missing_inlier)\n",
    "print(\"failed_inliers:\", failed_inliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동영상을 이미지로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 경로 설정\n",
    "output_dir = 'stable_005_video'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 동영상 파일 로드\n",
    "video = cv2.VideoCapture(\"stable_movie_005.mp4\")\n",
    "\n",
    "# 프레임 카운터 초기화\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # 동영상에서 프레임을 읽음\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break  # 동영상 끝에 도달하면 중단\n",
    "    \n",
    "    # 프레임을 이미지 파일로 저장\n",
    "    frame_filename = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    cv2.imwrite(frame_filename, frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "# 자원 해제\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidstab import VidStab\n",
    "\n",
    "# Using defaults\n",
    "stabilizer = VidStab()\n",
    "stabilizer.stabilize(input_path='movie_006.mp4', output_path='stable_movie_006.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 동영상으로\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 경로 설정\n",
    "folder = 'dump_demo_sequence/'\n",
    "\n",
    "# 동영상 저장 경로 설정\n",
    "output_video_path = 'result_origin.mp4'\n",
    "\n",
    "# 동영상 속성 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정 (XVID를 사용하면 AVI 형식으로 저장)\n",
    "fps = 30.0  # 초당 프레임 수\n",
    "frame_width = 320  # 프레임 너비\n",
    "frame_height = 480  # 프레임 높이\n",
    "\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "i = 0\n",
    "for name in os.listdir(folder):\n",
    "    img = cv2.imread(os.path.join(folder, name))\n",
    "    \n",
    "    cv2.imshow('frame', img)\n",
    "    \n",
    "    # 프레임을 동영상에 추가\n",
    "    out.write(img)\n",
    "    \n",
    "    \n",
    "    # 종료 키 입력 확인\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# 동영상 저장 종료\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "x = 319\n",
    "y = 184\n",
    "\n",
    "# 저장할 동영상 파일명 및 코덱 설정\n",
    "output_video_path = 'stabled_005.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_fps = 30.0  # 저장할 동영상의 프레임 속도\n",
    "\n",
    "cap = cv2.VideoCapture('stable_movie_005.mp4')\n",
    "image0 = load_image(\"img1.png\", grayscale=True)\n",
    "\n",
    "# 저장할 동영상의 너비와 높이 설정\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, output_video_fps, (frame_width, frame_height))\n",
    "\n",
    "count = 0\n",
    "\n",
    "# 각 프레임을 VideoWriter에 쓰기\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임에 작업 수행\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        continue\n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    image1 = stabilizer.stabilize_frame(input_frame = frame)\n",
    "    image1 = load_image(frame, grayscale=True)\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    \n",
    "    feats0, feats1, matches01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "    \n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "    \n",
    "    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n",
    "    if mask < 0.3:\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        continue\n",
    "    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "    #image0 = image1\n",
    "    \n",
    "    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # 동영상 파일에 프레임 추가\n",
    "    out.write(frame)\n",
    "\n",
    "    # 화면에 표시\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # 종료 키 입력 확인\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# VideoWriter 객체 해제\n",
    "out.release()\n",
    "\n",
    "# VideoCapture 객체 해제\n",
    "cap.release()\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m kpts0, kpts1, matches \u001b[38;5;241m=\u001b[39m feats0[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m], feats1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m], matches01[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     45\u001b[0m m_kpts0, m_kpts1 \u001b[38;5;241m=\u001b[39m kpts0[matches[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]], kpts1[matches[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m---> 47\u001b[0m homography, mask \u001b[38;5;241m=\u001b[39m \u001b[43mCSRansac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsransac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_kpts0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_kpts1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.3\u001b[39m:\n\u001b[0;32m     49\u001b[0m     out\u001b[38;5;241m.\u001b[39mwrite(frame)\n",
      "File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\CSRansac.py:46\u001b[0m, in \u001b[0;36mcsransac\u001b[1;34m(target_keypoint, frame_keypoint)\u001b[0m\n\u001b[0;32m     44\u001b[0m     frame_sample\u001b[38;5;241m.\u001b[39mappend(frame_keypoint[idx])\n\u001b[0;32m     45\u001b[0m     col, row \u001b[38;5;241m=\u001b[39m get_position(frame_keypoint[idx])\n\u001b[1;32m---> 46\u001b[0m     grid_list[row] \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#==================================================\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#CSP\u001b[39;00m\n\u001b[0;32m     49\u001b[0m m_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "x = 637 // 2\n",
    "y = 367 // 2\n",
    "\n",
    "# 저장할 동영상 파일명 및 코덱 설정\n",
    "output_video_path = 'lightglue_unstable_result.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_fps = 30.0  # 저장할 동영상의 프레임 속도\n",
    "\n",
    "cap = cv2.VideoCapture('demo_video.mp4')\n",
    "image0 = load_image(\"img0.png\", grayscale=True)\n",
    "\n",
    "# 저장할 동영상의 너비와 높이 설정\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, output_video_fps, (frame_width, frame_height))\n",
    "\n",
    "count = 0\n",
    "\n",
    "# 각 프레임을 VideoWriter에 쓰기\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임에 작업 수행\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        continue\n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    image1 = load_image(frame, grayscale=True)\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    \n",
    "    feats0, feats1, matches01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "    \n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "    \n",
    "    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n",
    "    if mask < 0.3:\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        continue\n",
    "    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "    #image0 = image1\n",
    "    \n",
    "    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # 동영상 파일에 프레임 추가\n",
    "    out.write(frame)\n",
    "\n",
    "    # 화면에 표시\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # 종료 키 입력 확인\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# VideoWriter 객체 해제\n",
    "out.release()\n",
    "\n",
    "# VideoCapture 객체 해제\n",
    "cap.release()\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 속도 측정(인접 프레임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames Processed: 367\n",
      "Average FPS: 12.47\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "x = 637 // 2\n",
    "y = 367 // 2\n",
    "\n",
    "image0 = load_image(\"img0.png\", grayscale=True)\n",
    "count = 0\n",
    "\n",
    "# 프레임 수 초기화\n",
    "frame_count = 0\n",
    "\n",
    "failed_inliers = 0\n",
    "\n",
    "# 프레임 별 처리 시간 리스트 초기화\n",
    "frame_processing_times = []\n",
    "\n",
    "cap = cv2.VideoCapture('demo_video_resized.mp4')\n",
    "\n",
    "# 각 프레임을 VideoWriter에 쓰기\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # 프레임에 작업 수행\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        \n",
    "        continue\n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    image1 = load_image(frame, grayscale=True)\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    \n",
    "    feats0, feats1, matches01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "    \n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "    \n",
    "    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n",
    "    if mask < 0.3:\n",
    "        failed_inliers += 1\n",
    "    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "    image0 = image1\n",
    "    \n",
    "    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # 현재 시간 측정\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # 프레임 처리 시간 계산\n",
    "    frame_processing_time = current_time - start_time\n",
    "    frame_processing_times.append(frame_processing_time)\n",
    "    \n",
    "    # 이전 프레임 처리 시간 업데이트\n",
    "    prev_frame_time = current_time\n",
    "\n",
    "    # FPS 계산\n",
    "    fps = 1.0 / frame_processing_time\n",
    "    \n",
    "    # 프레임 수 증가\n",
    "    frame_count += 1\n",
    "    \n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#전체 처리 시간 계산\n",
    "total_processing_time = sum(frame_processing_times)\n",
    "\n",
    "# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n",
    "average_fps = frame_count / total_processing_time\n",
    "\n",
    "print(f\"Total Frames Processed: {frame_count}\")\n",
    "print(f\"Average FPS: {average_fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 속도 측정 (타깃 프레임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames Processed: 368\n",
      "Average FPS: 7.35\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "x = 637 // 2\n",
    "y = 367 // 2\n",
    "\n",
    "image0 = load_image(\"img0.png\", grayscale=True)\n",
    "count = 0\n",
    "\n",
    "# 프레임 수 초기화\n",
    "frame_count = 0\n",
    "\n",
    "# 프레임 별 처리 시간 리스트 초기화\n",
    "frame_processing_times = []\n",
    "\n",
    "cap = cv2.VideoCapture('demo_video_resized.mp4')\n",
    "image0 = load_image(\"img0.png\", grayscale=True)\n",
    "\n",
    "# 각 프레임을 VideoWriter에 쓰기\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    image1 = load_image(frame, grayscale=True)\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    \n",
    "    feats0, feats1, matches01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "    \n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "    \n",
    "    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n",
    "    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "    #image0 = image1\n",
    "    \n",
    "    # 현재 시간 측정\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # 프레임 처리 시간 계산\n",
    "    frame_processing_time = current_time - start_time\n",
    "    frame_processing_times.append(frame_processing_time)\n",
    "    \n",
    "    # 이전 프레임 처리 시간 업데이트\n",
    "    prev_frame_time = current_time\n",
    "\n",
    "    # FPS 계산\n",
    "    fps = 1.0 / frame_processing_time\n",
    "    \n",
    "    # 프레임 수 증가\n",
    "    frame_count += 1\n",
    "    \n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#전체 처리 시간 계산\n",
    "total_processing_time = sum(frame_processing_times)\n",
    "\n",
    "# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n",
    "average_fps = frame_count / total_processing_time\n",
    "\n",
    "print(f\"Total Frames Processed: {frame_count}\")\n",
    "print(f\"Average FPS: {average_fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
