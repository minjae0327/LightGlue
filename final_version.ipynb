{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Matching and Homography Estimation with OpenCV and LightGlue"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2 \n","import time\n","import json\n","import math\n","import copy\n","import torch\n","import numpy as np\n","from vidstab import VidStab\n","import matplotlib.pyplot as plt\n","\n","from lightglue import viz2d\n","from lightglue import LightGlue, SuperPoint, DISK\n","from lightglue.utils import load_image, rbd, load_image_from_path\n","import CSRansac\n","\n","from vidstab import VidStab"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n","\n","extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n","#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n","matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n","#matcher.compile(mode='reduce-overhead')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.1.2\n","cuda\n"]}],"source":["print(torch.__version__)\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset 전처리"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["aircraft_datasets = \"datasets\"\n","\n","lables = os.path.join(aircraft_datasets + \"/label\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[319.172, 270.5525], [320.0, 265.2454], [344.4649, 256.0291], [313.5761, 257.2958], [325.4817, 168.0838], [315.9396, 202.4891], [325.4792, 168.0804], [312.3912, 306.4268], [320.0, 265.2386], [331.4872, 26.9028], [316.5232, 203.0878], [329.4775, 59.023], [320.0, 337.5758], [324.1364, 161.3599], [309.3466, 253.7444], [321.2631, 248.8727], [332.8524, 236.0226], [326.0481, 203.8017], [318.4895, 251.0605], [320.9647, 255.8256], [321.2552, 215.7061], [319.4533, 225.7516], [319.4534, 180.869], [321.2005, 215.6378], [321.2277, 215.6717], [316.3752, 230.084], [316.2056, 231.4328], [320.8982, 312.2862], [320.9509, 198.6214], [315.9281, 231.4998], [320.8952, 257.6141], [320.8216, 257.4771], [320.8206, 257.478], [320.6533, 290.0106], [320.7295, 257.2927], [320.0, 291.9199], [320.0, 257.736], [320.0, 485.3593], [318.0135, 279.4593], [314.6762, 328.5291]]\n","40\n","[[0.4987062, 0.563651], [0.5, 0.5525945], [0.5382264, 0.5333939999999999], [0.4899627, 0.5360328999999999], [0.5085652, 0.3501746], [0.4936557, 0.42185229999999996], [0.5085613, 0.3501674], [0.4881113, 0.6383890999999999], [0.5, 0.5525804999999999], [0.5179487, 0.056047599999999975], [0.4945675, 0.4230996], [0.5148086, 0.12296450000000003], [0.5, 0.703283], [0.5064632, 0.33616650000000003], [0.483354, 0.5286341], [0.5019736, 0.5184847], [0.5200818, 0.4917138], [0.5094502, 0.4245869], [0.4976398, 0.5230427], [0.5015073, 0.5329699], [0.5019613, 0.44938769999999995], [0.4991458, 0.4703159], [0.499146, 0.3768104], [0.5018758, 0.4492454], [0.5019183, 0.4493161], [0.4943362, 0.4793417], [0.4940712, 0.4821516], [0.5014035, 0.6505963], [0.5014858, 0.41379449999999995], [0.4936377, 0.48229120000000003], [0.5013987, 0.5366961], [0.5012838, 0.5364107], [0.5012822, 0.5364124], [0.5010208, 0.6041888], [0.5011398, 0.5360265], [0.5, 0.6081664], [0.5, 0.53695], [0.5, 1.01116514], [0.4968961, 0.5822069000000001], [0.4916815, 0.6844356]]\n","40\n"]}],"source":["# 원본 좌표값과 실수형 좌표값을 불러옴\n","origin_coordinate = []\n","float_origin_coordinate = []\n","\n","# 원점 좌표값 불러오기\n","for label_file in os.listdir(lables):\n","    label_path = os.path.join(lables, label_file)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        float_coord = copy.deepcopy(coord)\n","        float_origin_coordinate.append(float_coord)\n","        \n","        coord[0] = round(coord[0] * 640, 4)\n","        coord[1] = round(coord[1] * 480, 4)\n","        origin_coordinate.append(coord)\n","\n","print(origin_coordinate)\n","print(len(origin_coordinate))\n","\n","print(float_origin_coordinate)\n","print(len(float_origin_coordinate))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["video_dir = os.path.join(aircraft_datasets, \"video\")\n","target_image_dir = os.path.join(aircraft_datasets, \"target_image\")\n","# 비디오 안정화 객체 생성\n","stabilizer = VidStab()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#원본 이미지를 가져오는 코드\n","len_coord = len(origin_coordinate)\n","\n","target_images = []\n","for image_file in os.listdir(target_image_dir):\n","    image_path = os.path.join(target_image_dir, image_file)\n","    target_images.append(image_path)\n","\n","# 에러를 저장할 리스트\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def matching_keypoints(target_img, video_img, stabilizing=False):\n","    # 이미지를 불러옴\n","    img0 = load_image(target_img, grayscale=True)\n","    if stabilizing == True:\n","        img1 = stabilizer.stabilize_frame(video_img)\n","        img1 = load_image(img1, grayscale=True)\n","    else:\n","        img1 = load_image(video_img , grayscale=True)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","\n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","\n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","\n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }\n","    \n","#에러 측정 \n","def get_errors(disappear_error, misannotate_error, pixel_error, keypoint, mask, coord, x, y):\n","    if len(keypoint) < 6:\n","        missing_inlier += 1\n","    \n","    if mask == 0.3:\n","        failed_inliers += 1\n","    \n","    _x = coord[0] / 640\n","    _y = coord[1] / 480\n","    \n","    if _x < 0 or _x > 1 or _y < 0 or _y > 1:\n","        disappear_error += 1\n","        \n","    distance = math.sqrt((x - _x)**2 + (y - _y)**2)\n","    \n","    if distance > 0.1:\n","        misannotate_error += 1\n","        \n","    if distance > pixel_error:\n","        pixel_error = distance\n","        \n","    return {\n","        \"disappear_error\": disappear_error,\n","        \"misannotate_error\": misannotate_error,\n","        \"pixel_error\": pixel_error,\n","        \"missing_inlier\": missing_inlier,\n","        \"failed_inliers\": failed_inliers\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 매칭되는 호모그래피를 구하여 원점을 투영 변환한 후, 에러를 측정\n","# 에러 측정을 위해 총 10번 반복\n","for i in range(10):\n","    disappear_error = 0\n","    misannotate_error = 0\n","    pixel_error = 0\n","    \n","    for i in range(len_coord):\n","        target_image = target_images[i]\n","        len_target_image = len(target_images)\n","        \n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        target_image = load_image(target_image, grayscale=True)\n","        \n","        # vide_dir에 있는 모든 비디오를 가져옴\n","        for video_file in os.listdir(video_dir):\n","            video_path = os.path.join(video_dir, video_file)\n","            cap = cv2.VideoCapture(video_path)\n","            \n","            # 각 프레임 처리, 에러처리도 동시에 진행\n","            while True:\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                \n","                # 특징점 매칭\n","                results = matching_keypoints(target_image, frame)\n","                target_keypoint = results[\"points0\"].cpu().numpy()\n","                frame_keypoint = results[\"points1\"].cpu().numpy()\n","                \n","               # 호모그래피 추정\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint))\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","                \n","                # 에러 측정\n","                error_results = get_errors(disappear_error, misannotate_error, pixel_error, target_keypoint, mask, projected_pts, x, y)\n","                    \n","            cap.release()\n","\n","    disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","  "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 279.5\n","num_error: 867.2\n","pixel_error: 10.09973137927756\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)\n","print(\"missing_inlier:\", missing_inlier)\n","print(\"failed_inliers:\", failed_inliers)   "]},{"cell_type":"markdown","metadata":{},"source":["## check speed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# video_frames 폴더에서 프레임 파일 리스트 가져오기\n","video_frames = os.listdir('video')\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","# 프레임 별 처리 시간 리스트 초기화\n","frame_processing_times = []\n","\n","x = 637 // 2\n","y = 367 // 2\n","\n","image0 = load_image_from_path(\"img1.png\", grayscale=True)\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","# 각 프레임 처리\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    start_time = time.time()\n","    \n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = stabilizer.stabilize_frame(input_frame = frame)\n","    image1 = load_image(frame, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, _ = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","    \n","    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n","    \n","    # 현재 시간 측정\n","    current_time = time.time()\n","    \n","    # 프레임 처리 시간 계산\n","    frame_processing_time = current_time - start_time\n","    frame_processing_times.append(frame_processing_time)\n","    \n","    # 이전 프레임 처리 시간 업데이트\n","    prev_frame_time = current_time\n","\n","    # FPS 계산\n","    fps = 1.0 / frame_processing_time\n","\n","    # 프레임 수 증가\n","    frame_count += 1\n","\n","    \n","    cv2.imshow('frame', frame)\n","    \n","    key = cv2.waitKey(5)\n","    if key == 27:\n","        break\n","    \n","    \n","cap.release()\n","cv2.destroyAllWindows()\n","\n","# 전체 처리 시간 계산\n","total_processing_time = sum(frame_processing_times)\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from vidstab import VidStab\n","\n","# Using defaults\n","stabilizer = VidStab()\n","stabilizer.stabilize(input_path='demo_video_resized.mp4', output_path='stable_demo_video.mp4')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 0\n","misannotate_error: 334\n","pixel_error: 0.14165977565377297\n"]}],"source":["cap = cv2.VideoCapture('datasets/unstable_version.mp4')\n","\n","x = 319\n","y = 238\n","\n","disappear_error = 0\n","misannotate_error = 0\n","pixel_error = 0\n","\n","image0 = load_image(\"datasets/origin.png\", grayscale=True)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","out = cv2.VideoWriter('before_stabilize.avi', fourcc, 30, (640, 480))\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    feats0 = extractor.extract(image0.to(device))\n","    #image1 = stabilizer.stabilize_frame(input_frame = frame)\n","    image1 = load_image(frame, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    if mask < 0.3:\n","        cv2.imshow('frame', frame)\n","        continue\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","    \n","    _x = projected_pts[0] / 640\n","    _y = projected_pts[1] / 480\n","    \n","    # 에러 측정\n","    if _x < 0 or _x > 1 or _y < 0 or _y > 1:\n","        disappear_error += 1\n","        \n","    distance = math.sqrt((x / 640 - _x)**2 + (y / 640 - _y)**2)\n","    \n","    if distance > 0.1:\n","        misannotate_error += 1\n","        \n","    if distance > pixel_error:\n","        pixel_error = distance\n","    \n","    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n","    \n","    cv2.imshow('frame', frame)\n","    \n","    out.write(frame)\n","    \n","    key = cv2.waitKey(5)\n","    if key == 27:\n","        break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","print(\"disappear_error:\", disappear_error)\n","print(\"misannotate_error:\", misannotate_error)\n","print(\"pixel_error:\", pixel_error)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"ename":"error","evalue":"OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:124: error: (-215:Assertion failed) bmi && width >= 0 && height >= 0 && (bpp == 8 || bpp == 24 || bpp == 32) in function 'FillBitmapInfo'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[1;32mIn[39], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m     pixel_error \u001b[38;5;241m=\u001b[39m distance\n\u001b[0;32m     55\u001b[0m cv2\u001b[38;5;241m.\u001b[39mcircle(frame, (\u001b[38;5;28mint\u001b[39m(projected_pts[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(projected_pts[\u001b[38;5;241m1\u001b[39m])), \u001b[38;5;241m5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(frame)\n\u001b[0;32m     61\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m5\u001b[39m)\n","\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:124: error: (-215:Assertion failed) bmi && width >= 0 && height >= 0 && (bpp == 8 || bpp == 24 || bpp == 32) in function 'FillBitmapInfo'\n"]}],"source":["cap = cv2.VideoCapture('datasets/unstable_version.mp4')\n","\n","x = 319\n","y = 238\n","\n","disappear_error = 0\n","misannotate_error = 0\n","pixel_error = 0\n","\n","image0 = load_image(\"datasets/origin.png\", grayscale=True)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","out = cv2.VideoWriter('after_stabilize.avi', fourcc, 30, (640, 480))\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = stabilizer.stabilize_frame(input_frame = frame)\n","    image1 = load_image(image1, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    if mask < 0.3:\n","        cv2.imshow('frame', frame)\n","        continue\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","    \n","    _x = projected_pts[0] / 640\n","    _y = projected_pts[1] / 480\n","    \n","    # 에러 측정\n","    if _x < 0 or _x > 1 or _y < 0 or _y > 1:\n","        disappear_error += 1\n","        \n","    distance = math.sqrt((x / 640 - _x)**2 + (y / 640 - _y)**2)\n","    \n","    if distance > 0.1:\n","        misannotate_error += 1\n","        \n","    if distance > pixel_error:\n","        pixel_error = distance\n","    \n","    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n","    \n","    cv2.imshow('frame', frame)\n","    \n","    out.write(frame)\n","    \n","    key = cv2.waitKey(5)\n","    if key == 27:\n","        break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","print(\"disappear_error:\", disappear_error)\n","print(\"misannotate_error:\", misannotate_error)\n","print(\"pixel_error:\", pixel_error)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
