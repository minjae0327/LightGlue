{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Matching and Homography Estimation with OpenCV and LightGlue"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2 \n","import time\n","import json\n","import math\n","import torch\n","import numpy as np\n","from vidstab import VidStab\n","import matplotlib.pyplot as plt\n","\n","from lightglue import viz2d\n","from lightglue import LightGlue, SuperPoint, DISK\n","from lightglue.utils import load_image, rbd, load_image_from_path\n","import CSRansac\n","\n","from vidstab import VidStab"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n","\n","extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n","#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n","matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n","#matcher.compile(mode='reduce-overhead')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.1.2\n","cuda\n"]}],"source":["print(torch.__version__)\n","print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def match_lightglue(img0, img1):\n","    img0 = load_image(img0)\n","    img1 = load_image(img1)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","    \n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","    \n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","        \n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["stabilizer = VidStab()\n","\n","def matching_keypoints(target_img, video_img, stabilizing=False):\n","    # 이미지를 불러옴\n","    img0 = load_image(target_img, grayscale=True)\n","    if stabilizing == True:\n","        img1 = cv2.imread(video_img)\n","        img1 = stabilizer.stabilize_frame(img1)\n","        img1 = load_image(img1, grayscale=True)\n","    else:\n","        img1 = load_image(video_img , grayscale=True)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","\n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","\n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","\n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset 전처리"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["aircraft_datasets = \"D:/aircraft_datasets\"\n","\n","lables = os.path.join(aircraft_datasets + \"/label\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[319.171968, 270.55248], [320.0, 265.24536], [344.464896, 256.02912], [313.576128, 257.29579199999995], [325.48172800000003, 168.083808], [315.939648, 202.48910399999997], [325.479232, 168.080352], [312.391232, 306.426768], [320.0, 265.23864], [331.487168, 26.902847999999988], [316.5232, 203.087808], [329.47750399999995, 59.02296000000001], [320.0, 337.57583999999997], [324.136448, 161.35992000000002], [309.34656, 253.744368], [321.263104, 248.872656], [332.852352, 236.02262399999998], [326.04812799999996, 203.801712], [318.48947200000003, 251.060496], [320.964672, 255.825552], [321.25523200000003, 215.70609599999997], [319.453312, 225.751632], [319.45344, 180.868992], [321.200512, 215.63779200000002], [321.227712, 215.671728], [316.37516800000003, 230.084016], [316.20556799999997, 231.432768], [320.89824, 312.286224], [320.950912, 198.62135999999998], [315.928128, 231.49977600000003], [320.895168, 257.614128], [320.82163199999997, 257.47713600000003], [320.820608, 257.477952], [320.653312, 290.010624], [320.729472, 257.29272], [320.0, 291.919872], [320.0, 257.736], [320.0, 485.3592672], [318.013504, 279.45931200000007], [314.67616, 328.529088]]\n","40\n"]}],"source":["origin_coordinate = []\n","\n","# 원점 좌표값 불러오기\n","for label_file in os.listdir(lables):\n","    label_path = os.path.join(lables, label_file)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        coord[0] = coord[0] * 640\n","        coord[1] = coord[1] * 480\n","        origin_coordinate.append(coord)\n","\n","print(origin_coordinate)\n","print(len(origin_coordinate))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["video_dir = os.path.join(aircraft_datasets, \"video\")\n","output_dir = os.path.join(aircraft_datasets, \"frames_from_video\")\n","stabilized_frame_path = os.path.join(aircraft_datasets, \"stabilized_frame\")\n","stabilizer = VidStab()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Frames Processed: 288\n","Average FPS: 7.06\n"]}],"source":["# video_frames 폴더에서 프레임 파일 리스트 가져오기\n","video_frames = os.listdir('video')\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","# 프레임 별 처리 시간 리스트 초기화\n","frame_processing_times = []\n","\n","x = 637 // 2\n","y = 367 // 2\n","\n","image0 = load_image_from_path(\"img1.png\", grayscale=True)\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","# 각 프레임 처리\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    start_time = time.time()\n","    \n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = stabilizer.stabilize_frame(input_frame = frame)\n","    image1 = load_image(frame, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, _ = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","    \n","    cv2.circle(frame, (int(projected_pts[0]), int(projected_pts[1])), 5, (0, 0, 255), -1)\n","    \n","    # 현재 시간 측정\n","    current_time = time.time()\n","    \n","    # 프레임 처리 시간 계산\n","    frame_processing_time = current_time - start_time\n","    frame_processing_times.append(frame_processing_time)\n","    \n","    # 이전 프레임 처리 시간 업데이트\n","    prev_frame_time = current_time\n","\n","    # FPS 계산\n","    fps = 1.0 / frame_processing_time\n","\n","    # 프레임 수 증가\n","    frame_count += 1\n","\n","    \n","    cv2.imshow('frame', frame)\n","    \n","    key = cv2.waitKey(5)\n","    if key == 27:\n","        break\n","    \n","    \n","cap.release()\n","cv2.destroyAllWindows()\n","\n","# 전체 처리 시간 계산\n","total_processing_time = sum(frame_processing_times)\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# #동영상에서 각 프레임을 이미지 파일로 저장하는 코드\n","# for video_filename in os.listdir(video_dir):\n","#     # video 파일 경로\n","#     video_path = os.path.join(video_dir, video_filename)\n","    \n","#     # video 파일 이름에서 확장자 제거하여 동영상 이름 추출\n","#     video_name = os.path.splitext(video_filename)[0]\n","    \n","#     # 해당 동영상의 프레임 저장 폴더 생성\n","#     video_output_dir = os.path.join(output_dir, video_name)\n","#     os.makedirs(video_output_dir, exist_ok=True)\n","    \n","#     # 동영상 파일 로드\n","#     video = cv2.VideoCapture(video_path)\n","\n","#     # 프레임 카운터 초기화\n","#     frame_count = 0\n","\n","#     while True:\n","#         # 동영상에서 프레임을 읽음\n","#         ret, frame = video.read()\n","#         if not ret:\n","#             break  # 동영상 끝에 도달하면 중단\n","        \n","#         # 프레임을 이미지 파일로 저장\n","#         frame_filename = os.path.join(video_output_dir, f'frame_{frame_count:04d}.jpg')\n","#         frame = cv2.resize(frame, (640, 480))\n","#         cv2.imwrite(frame_filename, frame)\n","        \n","#         frame_count += 1\n","\n","#     # 자원 해제\n","#     video.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# video_dir = os.path.join(aircraft_datasets, \"video\")\n","# output_dir = os.path.join(aircraft_datasets, \"frames_from_video\")\n","\n","# #동영상에서 각 프레임을 이미지 파일로 저장하는 코드\n","# for video_filename in os.listdir(video_dir):\n","#     # video 파일 경로\n","#     video_path = os.path.join(video_dir, video_filename)\n","    \n","#     # video 파일 이름에서 확장자 제거하여 동영상 이름 추출\n","#     video_name = os.path.splitext(video_filename)[0]\n","    \n","#     # 해당 동영상의 프레임 저장 폴더 생성\n","#     video_output_dir = os.path.join(output_dir, video_name)\n","#     os.makedirs(video_output_dir, exist_ok=True)\n","    \n","#     # 동영상 파일 로드\n","#     video = cv2.VideoCapture(video_path)\n","\n","#     # 프레임 카운터 초기화\n","#     frame_count = 0\n","\n","#     while True:\n","#         # 동영상에서 프레임을 읽음\n","#         ret, frame = video.read()\n","#         if not ret:\n","#             break  # 동영상 끝에 도달하면 중단\n","        \n","#         # 프레임을 이미지 파일로 저장\n","#         frame_filename = os.path.join(video_output_dir, f'frame_{frame_count:04d}.jpg')\n","#         frame = cv2.resize(frame, (640, 480))\n","#         cv2.imwrite(frame_filename, frame)\n","        \n","#         frame_count += 1\n","\n","#     # 자원 해제\n","#     video.release()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["368\n"]}],"source":["# 원본 이미지 경로를 저장할 리스트\n","images = [[] for i in range(len(origin_coordinate))]\n","i = 0\n","\n","# output_dir 내의 모든 폴더에 대한 반복\n","for folder_name in os.listdir(output_dir):\n","    folder_path = os.path.join(output_dir, folder_name)\n","    \n","    for name in os.listdir(folder_path):\n","        filename = os.path.join(folder_path, name)\n","        images[i].append(filename)\n","    \n","    i = i + 1\n","\n","# images 리스트의 길이 반환\n","# num_images = len(images)\n","# print(f\"총 이미지 수: {num_images}\")\n","\n","print(len(images[0]))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["#안정화된 동영상에서 프레임을 이미지 파일로 저장\n","stabilized_frame_path = os.path.join(aircraft_datasets, \"stabilized_frame\")\n","\n","#동영상에서 각 프레임을 이미지 파일로 저장하는 코드\n","for video_filename in os.listdir(stabilized_video_path):\n","    # video 파일 경로\n","    video_path = os.path.join(video_dir, video_filename)\n","    \n","    # video 파일 이름에서 확장자 제거하여 동영상 이름 추출\n","    video_name = os.path.splitext(video_filename)[0]\n","    \n","    # 해당 동영상의 프레임 저장 폴더 생성\n","    output_dir = os.path.join(stabilized_frame_path, video_name)\n","    os.makedirs(output_dir, exist_ok=True)\n","    \n","    # 동영상 파일 로드\n","    video = cv2.VideoCapture(video_path)\n","\n","    # 프레임 카운터 초기화\n","    frame_count = 0\n","\n","    while True:\n","        # 동영상에서 프레임을 읽음\n","        ret, frame = video.read()\n","        if not ret:\n","            break  # 동영상 끝에 도달하면 중단\n","        \n","        # 프레임을 이미지 파일로 저장\n","        frame_filename = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')\n","        frame = cv2.resize(frame, (640, 480))\n","        cv2.imwrite(frame_filename, frame)\n","        \n","        frame_count += 1\n","\n","    # 자원 해제\n","    video.release()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["# 안정화 이미지 경로를 저장할 리스트\n","stablized_images = [[] for i in range(len(origin_coordinate))]\n","i = 0\n","\n","# output_dir 내의 모든 폴더에 대한 반복\n","for folder_name in os.listdir(stabilized_frame_path):\n","    folder_path = os.path.join(stabilized_frame_path, folder_name)\n","    \n","    for name in os.listdir(folder_path):\n","        filename = os.path.join(folder_path, name)\n","        if os.path.isfile(filename):\n","            stablized_images[i].append(filename)\n","    \n","    i = i + 1\n","\n","print(len(stablized_images[0]))"]},{"cell_type":"markdown","metadata":{},"source":["## Compare Homography Matrices"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","for i in range(len_coord):\n","    _images = images[i]\n","    _len_images = len(_images)\n","    x = origin_coordinate[i][0]\n","    y = origin_coordinate[i][1]\n","    \n","    # 두 번째 차원의 리스트 초기화\n","    coord_list[i] = [[] for _ in range(_len_images)]\n","\n","    img0 = _images[0]\n","    for j in range(_len_images):\n","        if j != _len_images - 1:\n","            img1 = _images[j+1]\n","\n","            # LightGlue\n","            results_lightglue = match_lightglue(img0, img1, cfg.lightglue)\n","            target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","            frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","\n","            homography, _ = CSRansac.csransac(target_keypoint, frame_keypoint)\n","            projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","            coord_list[i][j].append(projected_pts)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# 각 행의 이름을 지정하기 위한 딕셔너리 생성\n","data_dict = {}\n","for i, row in enumerate(coord_list):\n","    key = f\"video_{i + 1}\"  # 각 행의 이름 생성 (row_1, row_2, ...)\n","    data_dict[key] = row\n","\n","filename = \"test_coord_list.json\"\n","file_path = os.path.join(aircraft_datasets, filename)\n","with open(file_path, \"w\") as f:\n","    json.dump(data_dict, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#안정화된 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","stable_coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","for i in range(len_coord):\n","    _stablized_images = stablized_images[i]\n","    _len_stablized_images= len(_stablized_images)\n","    x = origin_coordinate[i][0]\n","    y = origin_coordinate[i][1]\n","    \n","    stable_coord_list[i] = [[] for _j in range(_len_stablized_images)]\n","    \n","    img0 = _stablized_images[0]\n","    for j in range(_len_stablized_images):\n","        if j != _len_stablized_images - 1:\n","            img1 = _stablized_images[j+1]\n","        \n","            # LightGlue\n","            results_lightglue = match_lightglue(img0, img1, cfg.lightglue)\n","            target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","            frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","            \n","            homography, _ = CSRansac.csransac(target_keypoint, frame_keypoint)\n","            projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","            \n","            stable_coord_list[i][j].append(projected_pts)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# 각 행의 이름을 지정하기 위한 딕셔너리 생성\n","stabilized_data_dict = {}\n","for i, row in enumerate(stable_coord_list):\n","    key = f\"video_{i + 1}\"  # 각 행의 이름 생성 (row_1, row_2, ...)\n","    stabilized_data_dict[key] = row\n","\n","filename = \"test_stabilized_coord_list.json\"\n","file_path = os.path.join(aircraft_datasets, filename)\n","with open(file_path, \"w\") as f:\n","    json.dump(stabilized_data_dict, f, indent=4)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# #프레임을 동영상으로 만드는 코드\n","\n","# # 폴더 경로 설정\n","# folder = 'video'\n","\n","# # 동영상 저장 경로 설정\n","# output_video_path = 'result_origin.mp4'\n","\n","# # 동영상 속성 설정\n","# fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정 (XVID를 사용하면 AVI 형식으로 저장)\n","# fps = 30.0  # 초당 프레임 수\n","# frame_width = 640  # 프레임 너비\n","# frame_height = 480  # 프레임 높이\n","\n","# out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n","\n","# x = 637 // 2\n","# y = 367 // 2\n","\n","# i = 0\n","# for name in os.listdir(folder):\n","#     img = cv2.imread(os.path.join(folder, name))\n","#     if i == 0:\n","#         cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n","#     elif i == len_img - 1:\n","#         break\n","#     else:\n","#         x = round(coord_list[i][0])\n","#         y = round(coord_list[i][1])\n","#         cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n","\n","#     i = i + 1\n","    \n","#     # 프레임을 동영상에 추가\n","#     out.write(img)\n","\n","# # 동영상 저장 종료\n","# out.release()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Error Estimate"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.4987062, 0.563651], [0.5, 0.5525945], [0.5382264, 0.5333939999999999], [0.4899627, 0.5360328999999999], [0.5085652, 0.3501746], [0.4936557, 0.42185229999999996], [0.5085613, 0.3501674], [0.4881113, 0.6383890999999999], [0.5, 0.5525804999999999], [0.5179487, 0.056047599999999975], [0.4945675, 0.4230996], [0.5148086, 0.12296450000000003], [0.5, 0.703283], [0.5064632, 0.33616650000000003], [0.483354, 0.5286341], [0.5019736, 0.5184847], [0.5200818, 0.4917138], [0.5094502, 0.4245869], [0.4976398, 0.5230427], [0.5015073, 0.5329699], [0.5019613, 0.44938769999999995], [0.4991458, 0.4703159], [0.499146, 0.3768104], [0.5018758, 0.4492454], [0.5019183, 0.4493161], [0.4943362, 0.4793417], [0.4940712, 0.4821516], [0.5014035, 0.6505963], [0.5014858, 0.41379449999999995], [0.4936377, 0.48229120000000003], [0.5013987, 0.5366961], [0.5012838, 0.5364107], [0.5012822, 0.5364124], [0.5010208, 0.6041888], [0.5011398, 0.5360265], [0.5, 0.6081664], [0.5, 0.53695], [0.5, 1.01116514], [0.4968961, 0.5822069000000001], [0.4916815, 0.6844356]]\n","40\n","<class 'float'>\n"]}],"source":["float_origin_coordinate = []\n","lables = os.path.join(aircraft_datasets + \"/label\")\n","# 원점 좌표값 불러오기\n","for label in os.listdir(lables):\n","    label_path = os.path.join(lables, label)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        float_origin_coordinate.append(coord)\n","    \n","        \n","print(float_origin_coordinate)\n","print(len(float_origin_coordinate))\n","print(type(float_origin_coordinate[0][0]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","disappear_error: 14681\n","misannotate_error: 0\n","pixel_error: 0\n","missing_inlier: 110\n","failed_inliers: 126\n"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(1):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = match_lightglue(img0, img1)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    missing_inlier += 1\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask == 0.3:\n","                    failed_inliers += 1\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","    #에러 측정            \n","    disappear_error = 0\n","    misannotate_error = 0\n","    pixel_error = 0\n","\n","    for i in range(len_coord):\n","        float_origin_x = float_origin_coordinate[i][0]\n","        float_origin_y = float_origin_coordinate[i][1]\n","        \n","        origin_x = origin_coordinate[i][0]\n","        origin_y = origin_coordinate[i][1]\n","        \n","        for j in range(len(coord_list[i])-1):\n","            _coord = coord_list[i][j]\n","            \n","            x = _coord[0][0]\n","            y = _coord[0][1]\n","            \n","            _x = x / 640\n","            _y = y / 480\n","            \n","            _x = round(x, 4)\n","            _y = round(y, 4)\n","            \n","            # disappear_error\n","            if _x < 0 or _x > 1 or _y < 0 or _y > 1:\n","                disappear_error += 1\n","                continue\n","            \n","            float_distance = math.sqrt((float_origin_x - x)**2 + (float_origin_y - y)**2)\n","            \n","            # num_error\n","            if float_distance > 0.1:\n","                misannotate_error += 1\n","            \n","            distance = math.sqrt((origin_x - x)**2 + (origin_y - y)**2)\n","            # pixel_error\n","            if distance > pixel_error:\n","                pixel_error = distance\n","               \n","    print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","\n","print(\"missing_inlier:\", missing_inlier)\n","print(\"failed_inliers:\", failed_inliers)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 267.4\n","num_error: 855.6\n","pixel_error: 6.883285535124935\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"max(): Expected reduction dim 2 to have non-zero size.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m img1 \u001b[38;5;241m=\u001b[39m _images[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# LightGlue\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m results_lightglue \u001b[38;5;241m=\u001b[39m \u001b[43mmatching_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstabilizing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m target_keypoint \u001b[38;5;241m=\u001b[39m results_lightglue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     33\u001b[0m frame_keypoint \u001b[38;5;241m=\u001b[39m results_lightglue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n","Cell \u001b[1;32mIn[22], line 18\u001b[0m, in \u001b[0;36mmatching_keypoints\u001b[1;34m(target_img, video_img, stabilizing)\u001b[0m\n\u001b[0;32m     15\u001b[0m feats1 \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mextract(img1\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# match the features\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m matches01 \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats1\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m feats0, feats1, matches01 \u001b[38;5;241m=\u001b[39m [rbd(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [feats0, feats1, matches01]]  \u001b[38;5;66;03m# remove batch dimension\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# get results\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ailab\\anaconda3\\envs\\lightglue\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ailab\\anaconda3\\envs\\lightglue\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\lightglue.py:471\u001b[0m, in \u001b[0;36mLightGlue.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03mMatch keypoints and descriptors between two images\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    matches: List[[Si x 2]], scores: List[[Si]]\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mmp, device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\lightglue.py:582\u001b[0m, in \u001b[0;36mLightGlue._forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    580\u001b[0m desc0, desc1 \u001b[38;5;241m=\u001b[39m desc0[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :m, :], desc1[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n, :]  \u001b[38;5;66;03m# remove padding\u001b[39;00m\n\u001b[0;32m    581\u001b[0m scores, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_assignment[i](desc0, desc1)\n\u001b[1;32m--> 582\u001b[0m m0, m1, mscores0, mscores1 \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m matches, mscores \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(b):\n","File \u001b[1;32mc:\\Users\\ailab\\LightGlue\\lightglue\\lightglue.py:298\u001b[0m, in \u001b[0;36mfilter_matches\u001b[1;34m(scores, th)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_matches\u001b[39m(scores: torch\u001b[38;5;241m.\u001b[39mTensor, th: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"obtain matches from a log assignment matrix [Bx M+1 x N+1]\"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     max0, max1 \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m, scores[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    299\u001b[0m     m0, m1 \u001b[38;5;241m=\u001b[39m max0\u001b[38;5;241m.\u001b[39mindices, max1\u001b[38;5;241m.\u001b[39mindices\n\u001b[0;32m    300\u001b[0m     indices0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(m0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mm0\u001b[38;5;241m.\u001b[39mdevice)[\u001b[38;5;28;01mNone\u001b[39;00m]\n","\u001b[1;31mIndexError\u001b[0m: max(): Expected reduction dim 2 to have non-zero size."]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(1):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = matching_keypoints(img0, img1, stabilizing=True)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    missing_inlier += 1\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask == 0.3:\n","                    failed_inliers += 1\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","    #에러 측정            \n","    disappear_error = 0\n","    misannotate_error = 0\n","    pixel_error = 0\n","\n","    for i in range(len_coord):\n","        origin_x = float_origin_coordinate[i][0]\n","        origin_y = float_origin_coordinate[i][1]\n","        \n","        for j in range(len(coord_list[i])-1):\n","            _coord = coord_list[i][j]\n","            \n","            x = _coord[0][0]\n","            y = _coord[0][1]\n","            \n","            x = x / 640\n","            y = y / 480\n","            \n","            x = round(x, 4)\n","            y = round(y, 4)\n","            \n","            # disappear_error\n","            if x < 0 or x > 1 or y < 0 or y > 1:\n","                disappear_error += 1\n","                continue\n","            \n","            distance = math.sqrt((origin_x - x)**2 + (origin_y - y)**2)\n","            \n","            # num_error\n","            if distance > 0.1:\n","                misannotate_error += 1\n","            \n","            # pixel_error\n","            if distance > pixel_error:\n","                pixel_error = distance\n","               \n","    print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","\n","print(\"missing_inlier:\", missing_inlier)\n","print(\"failed_inliers:\", failed_inliers)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 279.5\n","num_error: 867.2\n","pixel_error: 10.09973137927756\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## check speed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# video_frames 폴더에서 프레임 파일 리스트 가져오기\n","video_frames = os.listdir('video')\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","# 프레임 별 처리 시간 리스트 초기화\n","frame_processing_times = []\n","\n","x = 637 // 2\n","y = 367 // 2\n","image0 = load_image(\"img1.png\", grayscale=True)\n","\n","# 각 프레임 처리\n","for frame in video_frames:\n","    start_time = time.time()\n","    \n","    #image0 = load_image(\"img1.png\", grayscale=True)\n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = load_image_from_path(os.path.join('video', frame), grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","\n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","\n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","\n","    # homography, _ = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    # projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","    # 현재 시간 측정\n","    current_time = time.time()\n","\n","    # 프레임 처리 시간 계산\n","    frame_processing_time = current_time - start_time\n","    frame_processing_times.append(frame_processing_time)\n","\n","    # 이전 프레임 처리 시간 업데이트\n","    prev_frame_time = current_time\n","\n","    # FPS 계산\n","    fps = 1.0 / frame_processing_time\n","\n","    # 프레임 수 증가\n","    frame_count += 1\n","\n","    # 이미지 및 매칭 시각화 코드 (생략)\n","\n","# 전체 처리 시간 계산\n","total_processing_time = sum(frame_processing_times)\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from vidstab import VidStab\n","\n","# Using defaults\n","stabilizer = VidStab()\n","stabilizer.stabilize(input_path='demo_video_resized.mp4', output_path='stable_demo_video.mp4')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
