<<<<<<< Updated upstream
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Matching and Homography Estimation with OpenCV and LightGlue"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2 \n","import time\n","import json\n","import math\n","import torch\n","import numpy as np\n","from vidstab import VidStab\n","import matplotlib.pyplot as plt\n","\n","from lightglue import viz2d\n","from lightglue import LightGlue, SuperPoint, DISK\n","from lightglue.utils import load_image, rbd, load_image_from_path\n","import CSRansac"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["device = torch.device(\"mps\")  # 'mps', 'cpu'\n","\n","extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n","#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n","matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n","#matcher.compile(mode='reduce-overhead')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.2.0\n","mps\n"]}],"source":["print(torch.__version__)\n","print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def match_lightglue(img0, img1):\n","    img0 = load_image(img0)\n","    img1 = load_image(img1)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","    \n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","    \n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","        \n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["stabilizer = VidStab()\n","\n","def matching_keypoints(target_img, video_img, stabilizing=False):\n","    # 이미지를 불러옴\n","    img0 = load_image(target_img, grayscale=True)\n","    if stabilizing == True:\n","        img1 = cv2.imread(video_img)\n","        img1 = stabilizer.stabilize_frame(img1)\n","        img1 = load_image(img1, grayscale=True)\n","    else:\n","        img1 = load_image(video_img , grayscale=True)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","\n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","\n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","\n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset 전처리"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["aircraft_datasets = \"datasets\"\n","\n","lables = os.path.join(aircraft_datasets + \"/label\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[316.20556799999997, 231.432768], [320.82163199999997, 257.47713600000003], [316.5232, 203.087808], [325.479232, 168.080352], [315.939648, 202.48910399999997], [331.487168, 26.902847999999988], [320.820608, 257.477952], [315.928128, 231.49977600000003], [316.37516800000003, 230.084016], [332.852352, 236.02262399999998], [320.0, 485.3592672], [319.171968, 270.55248], [321.25523200000003, 215.70609599999997], [320.653312, 290.010624], [320.729472, 257.29272], [320.964672, 255.825552], [318.013504, 279.45931200000007], [321.263104, 248.872656], [344.464896, 256.02912], [309.34656, 253.744368], [320.0, 291.919872], [314.67616, 328.529088], [318.48947200000003, 251.060496], [319.45344, 180.868992], [319.453312, 225.751632], [326.04812799999996, 203.801712], [320.0, 257.736], [324.136448, 161.35992000000002], [320.0, 265.24536], [320.0, 265.23864], [321.227712, 215.671728], [325.48172800000003, 168.083808], [320.0, 337.57583999999997], [320.950912, 198.62135999999998], [320.89824, 312.286224], [329.47750399999995, 59.02296000000001], [313.576128, 257.29579199999995], [321.200512, 215.63779200000002], [320.895168, 257.614128], [312.391232, 306.426768]]\n","40\n"]}],"source":["origin_coordinate = []\n","\n","# 원점 좌표값 불러오기\n","for label_file in os.listdir(lables):\n","    label_path = os.path.join(lables, label_file)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        coord[0] = coord[0] * 640\n","        coord[1] = coord[1] * 480\n","        origin_coordinate.append(coord)\n","\n","print(origin_coordinate)\n","print(len(origin_coordinate))\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.4940712, 0.4821516], [0.5012838, 0.5364107], [0.4945675, 0.4230996], [0.5085613, 0.3501674], [0.4936557, 0.42185229999999996], [0.5179487, 0.056047599999999975], [0.5012822, 0.5364124], [0.4936377, 0.48229120000000003], [0.4943362, 0.4793417], [0.5200818, 0.4917138], [0.5, 1.01116514], [0.4987062, 0.563651], [0.5019613, 0.44938769999999995], [0.5010208, 0.6041888], [0.5011398, 0.5360265], [0.5015073, 0.5329699], [0.4968961, 0.5822069000000001], [0.5019736, 0.5184847], [0.5382264, 0.5333939999999999], [0.483354, 0.5286341], [0.5, 0.6081664], [0.4916815, 0.6844356], [0.4976398, 0.5230427], [0.499146, 0.3768104], [0.4991458, 0.4703159], [0.5094502, 0.4245869], [0.5, 0.53695], [0.5064632, 0.33616650000000003], [0.5, 0.5525945], [0.5, 0.5525804999999999], [0.5019183, 0.4493161], [0.5085652, 0.3501746], [0.5, 0.703283], [0.5014858, 0.41379449999999995], [0.5014035, 0.6505963], [0.5148086, 0.12296450000000003], [0.4899627, 0.5360328999999999], [0.5018758, 0.4492454], [0.5013987, 0.5366961], [0.4881113, 0.6383890999999999]]\n","40\n","<class 'float'>\n"]}],"source":["float_origin_coordinate = []\n","lables = os.path.join(aircraft_datasets + \"/label\")\n","# 원점 좌표값 불러오기\n","for label in os.listdir(lables):\n","    label_path = os.path.join(lables, label)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        float_origin_coordinate.append(coord)\n","    \n","        \n","print(float_origin_coordinate)\n","print(len(float_origin_coordinate))\n","print(type(float_origin_coordinate[0][0]))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["video_dir = os.path.join(aircraft_datasets, \"video\")\n","output_dir = os.path.join(aircraft_datasets, \"frames_from_video\")\n","stabilized_frame_path = os.path.join(aircraft_datasets, \"stabilized_frame\")\n","stabilizer = VidStab()"]},{"cell_type":"markdown","metadata":{},"source":["## Error Estimate"]},{"cell_type":"markdown","metadata":{},"source":["## 기존 에러 평가 코드(타깃 이미지)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'images' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 좌표의 개수(동영상의 개수)만큼 반복\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_coord):\n\u001b[0;32m---> 17\u001b[0m         _images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m[i]\n\u001b[1;32m     18\u001b[0m         _len_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_images)\n\u001b[1;32m     19\u001b[0m         x \u001b[38;5;241m=\u001b[39m origin_coordinate[i][\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(10):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = match_lightglue(img0, img1)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    missing_inlier += 1\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask == 0.3:\n","                    failed_inliers += 1\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","    #에러 측정            \n","    disappear_error = 0\n","    misannotate_error = 0\n","    pixel_error = 0\n","\n","    for i in range(len_coord):\n","        float_origin_x = float_origin_coordinate[i][0]\n","        float_origin_y = float_origin_coordinate[i][1]\n","        \n","        origin_x = origin_coordinate[i][0]\n","        origin_y = origin_coordinate[i][1]\n","        \n","        for j in range(len(coord_list[i])-1):\n","            _coord = coord_list[i][j]\n","            \n","            x = _coord[0][0]\n","            y = _coord[0][1]\n","            \n","            x = x / 640\n","            y = y / 480\n","            \n","            x = round(x, 4)\n","            y = round(y, 4)\n","            \n","            # disappear_error\n","            if x < 0 or x > 1 or y < 0 or y > 1:\n","                disappear_error += 1\n","            \n","            distance = math.sqrt((float_origin_x - x)**2 + (float_origin_y - y)**2)\n","            \n","            # num_error\n","            if distance > 0.1:\n","                misannotate_error += 1\n","                \n","            # pixel_error\n","            if distance > pixel_error:\n","                pixel_error = distance\n","               \n","    print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","\n","print(\"missing_inlier:\", missing_inlier)\n","print(\"failed_inliers:\", failed_inliers)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 267.4\n","num_error: 855.6\n","pixel_error: 6.883285535124935\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 기존 에러 평가 코드(인접 프레임)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'images' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 좌표의 개수(동영상의 개수)만큼 반복\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_coord):\n\u001b[0;32m---> 17\u001b[0m         _images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m[i]\n\u001b[1;32m     18\u001b[0m         _len_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_images)\n\u001b[1;32m     19\u001b[0m         x \u001b[38;5;241m=\u001b[39m origin_coordinate[i][\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(10):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    failed_inliers += 1\n","                    continue\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask < 0.3:\n","                    failed_inliers += 1\n","                # projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                # coord_list[i][j].append(projected_pts)\n","                \n","                img0 = img1\n","                \n","#     #에러 측정            \n","#     disappear_error = 0\n","#     misannotate_error = 0\n","#     pixel_error = 0\n","\n","#     for i in range(len_coord):\n","#         origin_x = float_origin_coordinate[i][0]\n","#         origin_y = float_origin_coordinate[i][1]\n","        \n","#         for j in range(len(coord_list[i])-1):\n","#             _coord = coord_list[i][j]\n","            \n","#             x = _coord[0][0]\n","#             y = _coord[0][1]\n","            \n","#             x = x / 640\n","#             y = y / 480\n","            \n","#             x = round(x, 4)\n","#             y = round(y, 4)\n","            \n","#             # disappear_error\n","#             if x < 0 or x > 1 or y < 0 or y > 1:\n","#                 disappear_error += 1\n","            \n","#             distance = math.sqrt((origin_x - x)**2 + (origin_y - y)**2)\n","            \n","#             # num_error\n","#             if distance > 0.1:\n","#                 misannotate_error += 1\n","            \n","#             # pixel_error\n","#             if distance > pixel_error:\n","#                 pixel_error = distance\n","               \n","#     print(\"disappear_error:\", disappear_error)\n","#     print(\"misannotate_error:\", misannotate_error)\n","#     print(\"pixel_error:\", pixel_error)\n","\n","#     disappear_errors.append(disappear_error)\n","#     misannotate_errors.append(misannotate_error)\n","#     pixel_errors.append(pixel_error)\n","    \n","\n","# print(\"missing_inlier:\", missing_inlier)\n","# print(\"failed_inliers:\", failed_inliers)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 355.8\n","num_error: 0.0\n","pixel_error: 0.06434446666549035\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 비디오 inlier rate 출력"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["x = 637 / 2\n","y = 367 / 2\n","\n","image0 = load_image_from_path(\"img0.png\", grayscale=True)\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","inlier_rates = []\n","\n","# 각 프레임 처리\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = load_image(frame, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, mask = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    inlier_rates.append(mask)\n","    \n","    image0 = image1"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.287109375, 0.27310924369747897, 0.29894736842105263, 0.2982062780269058, 0.2871900826446281, 0.3063063063063063, 0.31390134529147984, 0.29930394431554525, 0.3085339168490153, 0.2913752913752914, 0.3047619047619048, 0.33658536585365856, 0.2962085308056872, 0.2711864406779661, 0.28078817733990147, 0.2967581047381546, 0.3027295285359802, 0.30412371134020616, 0.2845744680851064, 0.3018867924528302, 0.30749354005167956, 0.2807486631016043, 0.30684931506849317, 0.2724795640326976, 0.2905027932960894, 0.3086053412462908, 0.2976190476190476, 0.3392857142857143, 0.3333333333333333, 0.3606060606060606, 0.3353115727002967, 0.2966666666666667, 0.2826747720364742, 0.32407407407407407, 0.3176470588235294, 0.3201320132013201, 0.2897196261682243, 0.3202614379084967, 0.3106796116504854, 0.2833333333333333, 0.30434782608695654, 0.327217125382263, 0.28125, 0.3496932515337423, 0.30124223602484473, 0.32, 0.32167832167832167, 0.29473684210526313, 0.2973856209150327, 0.28618421052631576, 0.2909698996655518, 0.29931972789115646, 0.2803030303030303, 0.33204633204633205, 0.30685920577617326, 0.24372759856630824, 0.24372759856630824, 0.3014705882352941, 0.3401639344262295, 0.2600732600732601, 0.2690909090909091, 0.28363636363636363, 0.23465703971119134, 0.3112033195020747, 0.22580645161290322, 0.2572614107883817, 0.23715415019762845, 0.25, 0.2857142857142857, 0.2554112554112554, 0.2623762376237624, 0.25396825396825395, 0.30158730158730157, 0.23129251700680273, 0.2222222222222222, 0.24390243902439024, 0.24812030075187969, 0.20673076923076922, 0.1989795918367347, 0.21428571428571427, 0.2087912087912088, 0.23469387755102042, 0.216, 0.25675675675675674, 0.18705035971223022, 0.24107142857142858, 0.31666666666666665, 0.2714285714285714, 0.273972602739726, 0.30158730158730157, 0.2753623188405797, 0.30434782608695654, 0.27692307692307694, 0.2558139534883721, 0.25, 0.20652173913043478, 0.23076923076923078, 0.25252525252525254, 0.24742268041237114, 0.2558139534883721, 0.2116788321167883, 0.18518518518518517, 0.21296296296296297, 0.23711340206185566, 0.24050632911392406, 0.23529411764705882, 0.19883040935672514, 0.21965317919075145, 0.24352331606217617, 0.27419354838709675, 0.2556390977443609, 0.24545454545454545, 0.26519337016574585, 0.2606837606837607, 0.22488038277511962, 0.2183406113537118, 0.2669172932330827, 0.25, 0.2601626016260163, 0.27734375, 0.2768595041322314, 0.28444444444444444, 0.284, 0.28063241106719367, 0.29457364341085274, 0.30859375, 0.27756653992395436, 0.27756653992395436, 0.2974137931034483, 0.24324324324324326, 0.2826086956521739, 0.30038022813688214, 0.27636363636363637, 0.2923076923076923, 0.30743243243243246, 0.32971014492753625, 0.3013698630136986, 0.27526132404181186, 0.288961038961039, 0.35135135135135137, 0.29965156794425085, 0.3053691275167785, 0.2783171521035599, 0.30293159609120524, 0.265993265993266, 0.2771929824561403, 0.30491803278688523, 0.29874213836477986, 0.31446540880503143, 0.284789644012945, 0.3201219512195122, 0.28802588996763756, 0.28802588996763756, 0.30959752321981426, 0.3006134969325153, 0.2835820895522388, 0.3018292682926829, 0.31901840490797545, 0.2869822485207101, 0.281437125748503, 0.2947976878612717, 0.28212290502793297, 0.2945945945945946, 0.29444444444444445, 0.2761394101876676, 0.271505376344086, 0.2622107969151671, 0.29896907216494845, 0.288265306122449, 0.28607594936708863, 0.2765432098765432, 0.3, 0.29411764705882354, 0.29453681710213775, 0.2853932584269663, 0.2786885245901639, 0.3028169014084507, 0.2971698113207547, 0.3356164383561644, 0.3080459770114943, 0.30117647058823527, 0.28805620608899296, 0.3076923076923077, 0.31567328918322296, 0.3230769230769231, 0.29782608695652174, 0.30387931034482757, 0.31521739130434784, 0.3304157549234136, 0.3390191897654584, 0.30655391120507397, 0.3130081300813008, 0.35040983606557374, 0.3264033264033264, 0.35051546391752575, 0.33608247422680415, 0.358, 0.37328094302554027, 0.3477406679764244, 0.3501006036217304, 0.3509803921568627, 0.3720472440944882, 0.36622390891840606, 0.35514018691588783, 0.36259541984732824, 0.36685288640595903, 0.3722627737226277, 0.4040219378427788, 0.3877917414721723, 0.3763440860215054, 0.36769759450171824, 0.38956521739130434, 0.3732394366197183, 0.3879310344827586, 0.4053156146179402, 0.4317032040472175, 0.46905537459283386, 0.4317032040472175, 0.4064, 0.4838709677419355, 0.4492063492063492, 0.49522292993630573, 0.4416796267496112, 0.5394321766561514, 0.48623853211009177, 0.5039123630672926, 0.5513196480938416, 0.5339233038348082, 0.5327380952380952, 0.5078459343794579, 0.5099431818181818, 0.6271428571428571, 0.5896032831737346, 0.4951048951048951, 0.644, 0.6016150740242261, 0.5672823218997362, 0.6666666666666666, 0.6435897435897436, 0.7011642949547219, 0.6277641277641277, 0.6845386533665836, 0.7142857142857143, 0.7958937198067633, 0.7801418439716312, 0.7318501170960188, 0.7763761467889908, 0.8208616780045351, 0.9502824858757062, 0.803921568627451, 0.9445525291828794, 0.984488107549121, 0.8724035608308606, 0.9851632047477745, 0.994535519125683, 0.9621890547263682, 0.9484126984126984, 0.9811912225705329, 0.8664627930682977, 0.7202572347266881, 0.9554831704668838, 0.9042316258351893, 0.8720682302771855, 0.8250564334085779, 0.7782805429864253, 0.764018691588785, 0.7494407158836689, 0.7341040462427746, 0.731764705882353, 0.651307596513076, 0.7353658536585366, 0.6971214017521903, 0.6282527881040892, 0.7060333761232349, 0.5947955390334573, 0.6553030303030303, 0.6599496221662469, 0.6298200514138818, 0.6737235367372354, 0.710126582278481, 0.7220125786163522, 0.7121401752190237, 0.6510480887792849, 0.7682038834951457, 0.808433734939759, 0.7351543942992874, 0.8358556461001164, 0.8644859813084113, 0.8766006984866124, 0.8983833718244804, 0.8314732142857143, 0.9385665529010239, 0.9052396878483835, 0.9053318824809575, 0.9958549222797928, 0.9829968119022316, 0.998001998001998, 0.9833333333333333, 0.9853249475890985, 0.9967914438502674, 0.9526372443487621, 0.9373601789709173, 0.844542447629548, 0.8868571428571429, 0.8667425968109339, 0.7112922002328289, 0.8111239860950173, 0.7437425506555423, 0.729794933655006, 0.752851711026616, 0.699017199017199, 0.7210796915167095, 0.6262626262626263, 0.6741130091984231, 0.6511627906976745, 0.5957446808510638, 0.6266846361185984, 0.5418918918918919, 0.5355191256830601, 0.5342657342657343, 0.6323119777158774, 0.5887323943661972, 0.5119887165021156, 0.5726618705035971, 0.4799426934097421, 0.5151975683890577, 0.5227963525835866, 0.4774774774774775, 0.4523076923076923, 0.4432348367029549, 0.4651898734177215, 0.4584664536741214, 0.43800322061191627, 0.43902439024390244, 0.4224683544303797, 0.40770465489566615, 0.4181523500810373, 0.43914473684210525, 0.35506003430531735, 0.40484429065743943, 0.3707052441229656, 0.38768115942028986, 0.3902439024390244, 0.4011090573012939, 0.3944954128440367, 0.38817005545286504, 0.35110294117647056, 0.369140625, 0.36237623762376237, 0.36327345309381237, 0.32245681381957775, 0.34462151394422313, 0.3568627450980392, 0.34685598377281945, 0.3300395256916996, 0.32796780684104626, 0.3475609756097561, 0.32525252525252524, 0.32193158953722334, 0.30357142857142855, 0.305327868852459, 0.3333333333333333, 0.3248407643312102, 0.3148936170212766, 0.3081896551724138, 0.29723991507430997, 0.30242825607064017, 0.31601731601731603]\n"]}],"source":["print(inlier_rates)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","\n","# # inlier rates 예시 데이터\n","inlier_rates = np.random.rand(368)  # 예시로 240개의 데이터를 랜덤으로 생성\n","\n","fig, ax = plt.subplots()\n","xdata, ydata = [], []\n","ln, = plt.plot([], [], 'r-', animated=True)\n","\n","def init():\n","    ax.set_xlim(0, 240)  # 프레임 수에 따라 조절\n","    ax.set_ylim(0, np.max(inlier_rates))  # inlier rate의 최댓값에 따라 y축 범위 조절\n","    return ln,\n","\n","def update(frame):\n","    xdata.append(frame)\n","    ydata.append(inlier_rates[frame])\n","    ln.set_data(xdata, ydata)\n","    return ln,\n","\n","ani = FuncAnimation(fig, update, frames=range(len(inlier_rates)),\n","                    init_func=init, blit=True, interval=(1000/30))\n","\n","plt.xlabel('Frame')\n","plt.ylabel('Inlier Rate')\n","plt.title('Inlier Rate Over Time')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/gt/wdmlmv_d6jl1q6cvjxq5n_w00000gn/T/ipykernel_94968/712137643.py:44: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n","  ax.set_xlim(0, frame_count)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (1,) and (2,)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m inlier_rates_y\u001b[38;5;241m.\u001b[39mappend(inlier_rate)\n\u001b[1;32m     40\u001b[0m ax\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 41\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minlier_rates_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInlier rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/lightglue/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n","File \u001b[0;32m~/anaconda3/envs/lightglue/lib/python3.12/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/lightglue/lib/python3.12/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (2,)"]}],"source":["import matplotlib.pyplot as plt\n","import cv2\n","\n","plt.ion()  # 인터랙티브 모드 활성화\n","\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","inlier_rates_y = []\n","\n","fig, ax = plt.subplots()\n","ax.set_xlabel('Frame')\n","ax.set_ylabel('Inlier rate')\n","ax.set_xlim(0, None)\n","ax.set_ylim(0, 1.0)\n","\n","frame_count = 0\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = stabilizer.stabilize_frame(input_frame = frame)\n","    image1 = load_image(frame, grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","    \n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    \n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","    \n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","    \n","    homography, inlier_rate = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    \n","    inlier_rates_y.append(inlier_rate)\n","    \n","    ax.clear()\n","    ax.plot(frame_count, inlier_rates_y)\n","    ax.set_xlabel('Frame')\n","    ax.set_ylabel('Inlier rate')\n","    ax.set_xlim(0, frame_count)\n","    ax.set_ylim(0, 1.0)\n","    plt.pause(0.01)\n","    \n","    frame_count += 1\n","\n","plt.ioff()  # 인터랙티브 모드 비활성화\n","plt.show()\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"unsupported operand type(s) for -: 'list' and 'int'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     redDot\u001b[38;5;241m.\u001b[39mset_data(frame, frame)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m redDot\n\u001b[0;32m---> 17\u001b[0m ani \u001b[38;5;241m=\u001b[39m FuncAnimation(fig, animate, frames\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","\n","fig = plt.figure()\n","ax = plt.axes(xlim=(0, 3), ylim=(0, 9))\n","\n","a = np.arange(0, 3, 0.2)\n","ax.plot(a, a**2)\n","\n","redDot, = plt.plot([],[], 'ro')\n","\n","def animate(frame):\n","    redDot.set_data(frame, frame)\n","    return redDot\n","\n","ani = FuncAnimation(fig, animate, frames=np.arange([0.2, 0.4, 0.6]))\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## check speed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 테스트용\n","\n","# video_frames 폴더에서 프레임 파일 리스트 가져오기\n","video_frames = os.listdir('video')\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","# 프레임 별 처리 시간 리스트 초기화\n","frame_processing_times = []\n","\n","x = 637 // 2\n","y = 367 // 2\n","image0 = load_image(\"img1.png\", grayscale=True)\n","\n","# 각 프레임 처리\n","for frame in video_frames:\n","    start_time = time.time()\n","    \n","    #image0 = load_image(\"img1.png\", grayscale=True)\n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = load_image_from_path(os.path.join('video', frame), grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","\n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","\n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","\n","    homography, _ = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","    # 현재 시간 측정\n","    current_time = time.time()\n","\n","    # 프레임 처리 시간 계산\n","    frame_processing_time = current_time - start_time\n","    frame_processing_times.append(frame_processing_time)\n","\n","    # 이전 프레임 처리 시간 업데이트\n","    prev_frame_time = current_time\n","\n","    # FPS 계산\n","    fps = 1.0 / frame_processing_time\n","\n","    # 프레임 수 증가\n","    frame_count += 1\n","\n","    # 이미지 및 매칭 시각화 코드 (생략)\n","\n","# 전체 처리 시간 계산\n","total_processing_time = sum(frame_processing_times)\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from vidstab import VidStab\n","\n","# Using defaults\n","stabilizer = VidStab()\n","stabilizer.stabilize(input_path='demo_video_resized.mp4', output_path='stable_demo_video.mp4')"]},{"cell_type":"markdown","metadata":{},"source":["## 실험 데이터셋 재생 코드"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9755434782608695\n","0.6622983870967742\n","0.8769551616266945\n","-1\n","0.9988439306358381\n","-1\n","0.8955223880597015\n","-1\n","0.9721485411140584\n","0.9660056657223796\n","0.9686162624821684\n","0.3789173789173789\n","0.8782234957020058\n","0.9985250737463127\n","0.7752293577981652\n","0.9968992248062015\n","0.9968553459119497\n","0.9542682926829268\n","-1\n","0.37285491419656785\n","0.8927444794952681\n","0.913961038961039\n","0.9984202211690363\n","0.9984615384615385\n","-1\n","0.9984177215189873\n","0.9403225806451613\n","0.9268680445151033\n","0.9616564417177914\n","0.9667721518987342\n","0.8056338028169014\n","0.8379160636758322\n","0.5329428989751098\n","0.9357664233576642\n","0.9954476479514416\n","0.9204892966360856\n","0.5672782874617737\n","0.9405646359583952\n","0.2556732223903177\n","0.974124809741248\n","0.9969135802469136\n","0.9827856025039123\n","0.9953846153846154\n","0.9426356589147287\n","-1\n","-1\n","-1\n","0.9984375\n","0.9301948051948052\n","-1\n","0.9984472049689441\n","0.998468606431853\n","0.8180404354587869\n","-1\n","0.9165378670788253\n","-1\n","0.9877862595419847\n","0.9909502262443439\n","0.4391371340523883\n","0.9983766233766234\n","0.9986225895316805\n","0.992867332382311\n","0.9914651493598862\n","0.9548104956268222\n","0.7312138728323699\n","0.9324522760646109\n","0.9985358711566618\n","0.9940387481371088\n","0.9925925925925926\n","0.7256637168141593\n","0.24963503649635035\n","0.9985228951255539\n","0.8649851632047477\n","0.5198170731707317\n","0.9795918367346939\n","0.9985294117647059\n","-1\n","0.9970014992503748\n","0.04\n","0.9861963190184049\n","0.8967551622418879\n","-1\n","-1\n","0.9698795180722891\n","0.9478390461997019\n","0.962852897473997\n","0.977810650887574\n","-1\n","0.353204172876304\n","0.9921507064364207\n","-1\n","0.5563991323210412\n","0.9723756906077348\n","0.04028776978417266\n","0.7736686390532544\n","0.6641901931649331\n","0.9562043795620438\n","0.8546255506607929\n","0.9265785609397944\n","0.96875\n","0.9526717557251908\n","0.9984779299847792\n","0.8858858858858859\n","0.8688046647230321\n","0.9535232383808095\n","0.990726429675425\n","0.9652042360060514\n","0.9538690476190477\n","0.9123867069486404\n","-1\n","0.048484848484848485\n","0.9985380116959064\n","-1\n","0.5082458770614693\n","-1\n","0.948948948948949\n","-1\n","0.9788838612368024\n","0.9851632047477745\n","0.9355828220858896\n","0.9945872801082544\n","0.751060820367751\n","0.9986013986013986\n","0.97\n","0.9838945827232797\n","0.9939759036144579\n","0.9924357034795764\n","0.513595166163142\n","0.5962373371924746\n","-1\n","0.9461538461538461\n","0.44976816074188564\n","0.9843505477308294\n","0.6536661466458659\n","0.9212962962962963\n","-1\n","0.889060092449923\n","0.9772036474164134\n","0.9038167938931297\n","0.9984375\n","0.9663093415007658\n","0.9984662576687117\n","0.9290123456790124\n","0.9356814701378254\n","0.9813084112149533\n","0.9951298701298701\n","0.9622641509433962\n","-1\n","0.8732824427480916\n","0.9983443708609272\n","0.45072463768115945\n","0.9459459459459459\n","0.9895209580838323\n","0.8900602409638554\n","0.8582677165354331\n","0.9968051118210862\n","0.8592233009708737\n","-1\n","0.879746835443038\n","0.8743882544861338\n","0.9983579638752053\n","0.9761526232114467\n","0.9735202492211839\n","0.975346687211094\n","0.9724025974025974\n","0.6259780907668232\n","-1\n","0.9951845906902087\n","0.9824\n","0.6889952153110048\n","0.9934959349593496\n","-1\n","0.5543130990415336\n","0.1109350237717908\n","0.5917065390749602\n","0.8857142857142857\n","0.594679186228482\n","0.9423076923076923\n","0.9588138385502472\n","0.7953736654804271\n","0.9985141158989599\n","0.9862804878048781\n","-1\n","-1\n","0.9969418960244648\n","-1\n","0.9952755905511811\n","0.9983818770226537\n","0.9467554076539102\n","0.9786184210526315\n","0.912396694214876\n","0.8566666666666667\n","0.9530988274706867\n","0.9966273187183811\n","0.9565943238731218\n","0.9950980392156863\n","0.8964968152866242\n","0.9443561208267091\n","0.9697452229299363\n","-1\n","0.9984350547730829\n","0.9665605095541401\n","0.8682539682539683\n","0.9983766233766234\n","0.8847402597402597\n","-1\n","0.971107544141252\n","0.9884488448844885\n","0.8189233278955954\n","0.9807692307692307\n","0.9545454545454546\n","0.9904610492845787\n","0.9984326018808778\n","0.9588607594936709\n","0.7666666666666667\n","-1\n","0.9983818770226537\n","0.929159802306425\n","0.8909395973154363\n","0.9304635761589404\n","0.46353322528363045\n","0.9902597402597403\n","0.9682274247491639\n","0.9886914378029079\n","0.8605769230769231\n","0.9158576051779935\n","-1\n","0.9606557377049181\n","0.9968051118210862\n","-1\n","-1\n","0.8807947019867549\n","0.5472636815920398\n","0.998330550918197\n","0.9951534733441034\n","0.49917898193760263\n","0.9948805460750854\n","-1\n","0.9983818770226537\n","0.9873417721518988\n","0.5024390243902439\n","0.9903846153846154\n","-1\n","-1\n","0.9983471074380166\n","0.973109243697479\n","0.9915966386554622\n","-1\n","0.9188741721854304\n","0.9700499168053245\n","0.6427378964941569\n","-1\n","0.9983221476510067\n","0.9983333333333333\n","0.9947916666666666\n","0.8517887563884157\n","0.9844559585492227\n","0.9982847341337907\n","0.9879931389365352\n","0.9982993197278912\n","0.788659793814433\n","0.9947916666666666\n","-1\n","0.6007067137809188\n","0.8122866894197952\n","0.9966329966329966\n","0.9865996649916248\n","0.8682432432432432\n","0.38215488215488214\n","0.9963436928702011\n","0.9527687296416938\n","0.9965753424657534\n","-1\n","0.9982517482517482\n","-1\n","-1\n","0.9846678023850085\n","-1\n","-1\n","0.9483333333333334\n","0.9932203389830508\n","0.9883333333333333\n","0.6523235800344234\n","0.9965034965034965\n","0.9754385964912281\n","0.9875\n","0.9930191972076788\n","-1\n","-1\n","0.9982876712328768\n","0.9982847341337907\n","0.0798611111111111\n","0.9798319327731092\n","-1\n","0.9947183098591549\n","0.9492119089316988\n","0.7309644670050761\n","0.8836805555555556\n","0.7865546218487395\n","0.9946428571428572\n","0.9984\n","0.8723404255319149\n","0.7066666666666667\n","0.9886914378029079\n","0.9619205298013245\n","0.9948186528497409\n","0.9769736842105263\n","0.9983443708609272\n","0.942339373970346\n","0.9951298701298701\n","0.9536\n","0.9902755267423015\n","0.907563025210084\n","0.973421926910299\n","0.9834710743801653\n","-1\n","0.9983221476510067\n","0.30132450331125826\n","0.9967532467532467\n","0.9831932773109243\n","0.9590551181102362\n","0.7256198347107438\n","-1\n","0.6847290640394089\n","0.19224283305227655\n","0.7075163398692811\n","0.3310344827586207\n","0.9982993197278912\n","0.02508361204013378\n","0.998211091234347\n","0.9647435897435898\n","0.9949066213921901\n","0.9051580698835274\n","0.9721311475409836\n","0.8521594684385382\n","-1\n","0.9966722129783694\n","0.9816666666666667\n","0.9573070607553367\n","0.9900662251655629\n","0.5996649916247906\n","0.9704918032786886\n","0.973421926910299\n","-1\n","0.43243243243243246\n","0.9902439024390244\n","0.6693548387096774\n","0.998389694041868\n","0.38762214983713356\n","0.8625204582651391\n","0.9064039408866995\n","0.029508196721311476\n","-1\n","0.5903225806451613\n","0.9967105263157895\n","0.8433333333333334\n","0.9983388704318937\n","0.9983606557377049\n","0.9983079526226735\n","0.9551724137931035\n","0.716323296354992\n","-1\n","0.8388704318936877\n","0.9917218543046358\n","0.8727272727272727\n","-1\n","-1\n","failed_inliers: 67\n"]}],"source":["failed_inliers = 0\n","    \n","# 좌표의 개수(동영상의 개수)만큼 반복\n","for i in range(1):\n","    _images = images[0]\n","    _len_images = len(_images)\n","    x = origin_coordinate[0][0]\n","    y = origin_coordinate[0][1]\n","\n","    img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","    for j in range(_len_images):\n","        if j == 0:\n","            continue\n","        \n","        img1 = _images[j]\n","        _img1 = cv2.imread(img1)\n","\n","        # LightGlue\n","        results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n","        target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","        frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","\n","        homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","        print(mask)\n","        if mask < 0.3:\n","            failed_inliers += 1\n","            cv2.imshow('frame', _img1)\n","            img0 = img1\n","            continue\n","        projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","        \n","        img0 = img1\n","        \n","        cv2.circle(_img1, (int(projected_pts[0]), int(projected_pts[1])), 15, (0, 0, 255), -1)\n","        cv2.circle(_img1, (int(projected_pts[0]), int(projected_pts[1])), 3, (0, 0, 0), -1)\n","        cv2.imshow('frame', _img1)\n","        \n","        key = cv2.waitKey(5)\n","        if key == 27:\n","            break\n","            \n","cv2.destroyAllWindows()\n","print(\"failed_inliers:\", failed_inliers)\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_expo
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Matching and Homography Estimation with OpenCV and LightGlue"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2 \n","import time\n","import json\n","import math\n","import torch\n","import numpy as np\n","import kornia as K\n","import kornia.feature as KF\n","from vidstab import VidStab\n","\n","\n","from lightglue import LightGlue, SuperPoint, DISK\n","from lightglue.utils import load_image, rbd, load_image_from_path\n","import CSRansac"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n","#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n","matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n","#matcher.compile(mode='reduce-overhead')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.1.2\n","cuda\n"]}],"source":["print(torch.__version__)\n","print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def match_lightglue(img0, img1):\n","    img0 = load_image(img0)\n","    img1 = load_image(img1)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","    \n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","    \n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","        \n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def load_and_preprocess_image(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    image = cv2.resize(image, (640, 480))  # 필요한 경우 이미지 크기 조정\n","    image = K.image_to_tensor(image, False).float() / 255.0\n","    image = image.to(device)\n","    return image"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["stabilizer = VidStab()\n","\n","def matching_keypoints(target_img, video_img, stabilizing=False):\n","    # 이미지를 불러옴\n","    img0 = load_image(target_img, grayscale=True)\n","    if stabilizing == True:\n","        img1 = cv2.imread(video_img)\n","        img1 = stabilizer.stabilize_frame(img1)\n","        img1 = load_image(img1, grayscale=True)\n","    else:\n","        img1 = load_image(video_img , grayscale=True)\n","\n","    # extract local features\n","    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n","    feats1 = extractor.extract(img1.to(device))\n","\n","    # match the features\n","    matches01 = matcher({'image0': feats0, 'image1': feats1})\n","    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n","\n","    # get results\n","    kpts0 = feats0[\"keypoints\"]\n","    kpts1 = feats1[\"keypoints\"]\n","    matches = matches01['matches']  # indices with shape (K,2)\n","    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n","    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n","\n","    return {\n","        \"points0\": points0,\n","        \"points1\": points1,\n","    }"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_errors(coord_list, float_origin_coordinate, len_coord):\n","    misannotate_error = 0\n","    pixel_error = 0\n","    \n","    for i in range(len_coord):\n","        origin_x = float_origin_coordinate[i][0]\n","        origin_y = float_origin_coordinate[i][1]\n","        \n","        for j in range(len(coord_list[i])-1):\n","            _coord = coord_list[i][j]\n","            \n","            x = _coord[0][0]\n","            y = _coord[0][1]\n","            \n","            x = x / 640\n","            y = y / 480\n","            \n","            x = round(x, 4)\n","            y = round(y, 4)\n","            \n","            # disappear_error\n","            # if x < 0 or x > 1 or y < 0 or y > 1:\n","            #     disappear_error += 1\n","            \n","            distance = math.sqrt((origin_x - x)**2 + (origin_y - y)**2)\n","            \n","            # num_error\n","            if distance > 0.1:\n","                misannotate_error += 1\n","            \n","            # pixel_error\n","            if distance > pixel_error:\n","                pixel_error = distance\n","                \n","    return misannotate_error, pixel_error"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset 전처리"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["aircraft_datasets = \"D:/aircraft_datasets/\"\n","\n","lables = os.path.join(aircraft_datasets + \"label\")\n","video_dir = os.path.join(aircraft_datasets, \"video\")\n","stabilized_video_dir = os.path.join(aircraft_datasets, \"stabilized_video\")\n","stabilized_frame_dir = os.path.join(aircraft_datasets, \"stabilized_frame\")\n","target_image_dir = os.path.join(aircraft_datasets, \"target_image\")\n","# 비디오 안정화 객체 생성\n","stabilizer = VidStab()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[319.171968, 270.55248], [320.0, 265.24536], [344.464896, 256.02912], [313.576128, 257.29579199999995], [325.48172800000003, 168.083808], [315.939648, 202.48910399999997], [325.479232, 168.080352], [312.391232, 306.426768], [320.0, 265.23864], [331.487168, 26.902847999999988], [316.5232, 203.087808], [329.47750399999995, 59.02296000000001], [320.0, 337.57583999999997], [324.136448, 161.35992000000002], [309.34656, 253.744368], [321.263104, 248.872656], [332.852352, 236.02262399999998], [326.04812799999996, 203.801712], [318.48947200000003, 251.060496], [320.964672, 255.825552], [321.25523200000003, 215.70609599999997], [319.453312, 225.751632], [319.45344, 180.868992], [321.200512, 215.63779200000002], [321.227712, 215.671728], [316.37516800000003, 230.084016], [316.20556799999997, 231.432768], [320.89824, 312.286224], [320.950912, 198.62135999999998], [315.928128, 231.49977600000003], [320.895168, 257.614128], [320.82163199999997, 257.47713600000003], [320.820608, 257.477952], [320.653312, 290.010624], [320.729472, 257.29272], [320.0, 291.919872], [320.0, 257.736], [320.0, 485.3592672], [318.013504, 279.45931200000007], [314.67616, 328.529088]]\n","40\n"]}],"source":["origin_coordinate = []\n","\n","# 원점 좌표값 불러오기\n","for label_file in os.listdir(lables):\n","    label_path = os.path.join(lables, label_file)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        coord[0] = coord[0] * 640\n","        coord[1] = coord[1] * 480\n","        origin_coordinate.append(coord)\n","\n","print(origin_coordinate)\n","print(len(origin_coordinate))\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.4987062, 0.563651], [0.5, 0.5525945], [0.5382264, 0.5333939999999999], [0.4899627, 0.5360328999999999], [0.5085652, 0.3501746], [0.4936557, 0.42185229999999996], [0.5085613, 0.3501674], [0.4881113, 0.6383890999999999], [0.5, 0.5525804999999999], [0.5179487, 0.056047599999999975], [0.4945675, 0.4230996], [0.5148086, 0.12296450000000003], [0.5, 0.703283], [0.5064632, 0.33616650000000003], [0.483354, 0.5286341], [0.5019736, 0.5184847], [0.5200818, 0.4917138], [0.5094502, 0.4245869], [0.4976398, 0.5230427], [0.5015073, 0.5329699], [0.5019613, 0.44938769999999995], [0.4991458, 0.4703159], [0.499146, 0.3768104], [0.5018758, 0.4492454], [0.5019183, 0.4493161], [0.4943362, 0.4793417], [0.4940712, 0.4821516], [0.5014035, 0.6505963], [0.5014858, 0.41379449999999995], [0.4936377, 0.48229120000000003], [0.5013987, 0.5366961], [0.5012838, 0.5364107], [0.5012822, 0.5364124], [0.5010208, 0.6041888], [0.5011398, 0.5360265], [0.5, 0.6081664], [0.5, 0.53695], [0.5, 1.01116514], [0.4968961, 0.5822069000000001], [0.4916815, 0.6844356]]\n","40\n","<class 'float'>\n"]}],"source":["float_origin_coordinate = []\n","lables = os.path.join(aircraft_datasets + \"/label\")\n","# 원점 좌표값 불러오기\n","for label in os.listdir(lables):\n","    label_path = os.path.join(lables, label)\n","    with open(label_path, \"r\") as f:\n","        json_file = json.load(f)\n","        coord = json_file[\"targetAnnotation\"]\n","        float_origin_coordinate.append(coord)\n","    \n","        \n","print(float_origin_coordinate)\n","print(len(float_origin_coordinate))\n","print(type(float_origin_coordinate[0][0]))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["video_dir = os.path.join(aircraft_datasets, \"video\")\n","output_dir = os.path.join(aircraft_datasets, \"frames_from_video\")\n","stabilized_frame_path = os.path.join(aircraft_datasets, \"stabilized_frame\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["368\n"]}],"source":["# 원본 이미지 경로를 저장할 리스트\n","images = [[] for i in range(len(origin_coordinate))]\n","i = 0\n","\n","# output_dir 내의 모든 폴더에 대한 반복\n","for folder_name in os.listdir(output_dir):\n","    folder_path = os.path.join(output_dir, folder_name)\n","    \n","    for name in os.listdir(folder_path):\n","        filename = os.path.join(folder_path, name)\n","        images[i].append(filename)\n","    \n","    i = i + 1\n","\n","# images 리스트의 길이 반환\n","# num_images = len(images)\n","# print(f\"총 이미지 수: {num_images}\")\n","\n","print(len(images[0]))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["368\n"]}],"source":["stabilized_images = [[] for i in range(len(origin_coordinate))]\n","i = 0\n","\n","# output_dir 내의 모든 폴더에 대한 반복\n","for folder_name in os.listdir(stabilized_frame_path):\n","    folder_path = os.path.join(stabilized_frame_path, folder_name)\n","    \n","    for name in os.listdir(folder_path):\n","        filename = os.path.join(folder_path, name)\n","        stabilized_images[i].append(filename)\n","        \n","    i = i + 1\n","    \n","# images 리스트의 길이 반환\n","print(len(stabilized_images[0]))"]},{"cell_type":"markdown","metadata":{},"source":["## Error Estimate"]},{"cell_type":"markdown","metadata":{},"source":["## 기존 에러 평가 코드(타깃 이미지)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'images' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 좌표의 개수(동영상의 개수)만큼 반복\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_coord):\n\u001b[0;32m---> 17\u001b[0m         _images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m[i]\n\u001b[1;32m     18\u001b[0m         _len_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_images)\n\u001b[1;32m     19\u001b[0m         x \u001b[38;5;241m=\u001b[39m origin_coordinate[i][\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","missing_inlier = 0\n","failed_inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(10):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = match_lightglue(img0, img1)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    missing_inlier += 1\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask == 0.3:\n","                    failed_inliers += 1\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","    #에러 측정            \n","    disappear_error = 0\n","    misannotate_error = 0\n","    pixel_error = 0\n","\n","    for i in range(len_coord):\n","        float_origin_x = float_origin_coordinate[i][0]\n","        float_origin_y = float_origin_coordinate[i][1]\n","        \n","        origin_x = origin_coordinate[i][0]\n","        origin_y = origin_coordinate[i][1]\n","        \n","        for j in range(len(coord_list[i])-1):\n","            _coord = coord_list[i][j]\n","            \n","            x = _coord[0][0]\n","            y = _coord[0][1]\n","            \n","            x = x / 640\n","            y = y / 480\n","            \n","            x = round(x, 4)\n","            y = round(y, 4)\n","            \n","            # disappear_error\n","            if x < 0 or x > 1 or y < 0 or y > 1:\n","                disappear_error += 1\n","            \n","            distance = math.sqrt((float_origin_x - x)**2 + (float_origin_y - y)**2)\n","            \n","            # num_error\n","            if distance > 0.1:\n","                misannotate_error += 1\n","                \n","            # pixel_error\n","            if distance > pixel_error:\n","                pixel_error = distance\n","               \n","    print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","\n","print(\"missing_inlier:\", missing_inlier)\n","print(\"failed_inliers:\", failed_inliers)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["disappear_error: 267.4\n","num_error: 855.6\n","pixel_error: 6.883285535124935\n"]}],"source":["error1 = sum(disappear_errors) / len(disappear_errors)\n","error2 = sum(misannotate_errors) / len(misannotate_errors)\n","error3 = sum(pixel_errors) / len(pixel_errors)\n","\n","print(\"disappear_error:\", error1)\n","print(\"num_error:\", error2)\n","print(\"pixel_error:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드(인접 프레임)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 0\n","pixel_error: 0.058761471724418084\n","inliers: 305.45385315329554\n","failed_inliers: 955\n","zero_inliers: 0\n"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","failed_inliers = 0\n","zero_inliers = 0\n","\n","inliers = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(1):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    failed_inliers += 1\n","                    continue\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask <= 0.3:\n","                    if mask == 0:\n","                        zero_inliers += 1\n","                    failed_inliers += 1\n","                \n","                inliers += mask\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","                img0 = img1\n","                \n","    #에러 측정            \n","    # disappear_error = 0\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate)\n","               \n","    #print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    #disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","print(\"inliers:\", inliers / len(images))\n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드(이미지 안정화)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 0\n","pixel_error: 0.050013717660357865\n","misannotate_error: 1\n","pixel_error: 0.11768057115437372\n","misannotate_error: 0\n","pixel_error: 0.06512283939770747\n","misannotate_error: 0\n","pixel_error: 0.0671514593081909\n","misannotate_error: 0\n","pixel_error: 0.05411184712444778\n","misannotate_error: 0\n","pixel_error: 0.07403364800852379\n","misannotate_error: 0\n","pixel_error: 0.0734346283657758\n","misannotate_error: 0\n","pixel_error: 0.07215342899141808\n","misannotate_error: 0\n","pixel_error: 0.058189350256035645\n","misannotate_error: 0\n","pixel_error: 0.062043674997694934\n","inliers: 127355.83463355788\n","failed_inliers: 6783\n","zero_inliers: 0\n"]}],"source":["#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","failed_inliers = 0\n","zero_inliers = 0\n","\n","inliers = 0\n","\n","epochs = 10\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(epochs):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = stabilized_images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","\n","                # LightGlue\n","                results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n","                target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","                frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","                if len(target_keypoint) < 6:\n","                    failed_inliers += 1\n","                    continue\n","\n","                homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","                if mask <= 0.3:\n","                    if mask == 0:\n","                        zero_inliers += 1\n","                    failed_inliers += 1\n","                \n","                inliers += mask\n","                projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","                coord_list[i][j].append(projected_pts)\n","                \n","                img0 = img1\n","                \n","    #에러 측정            \n","    # disappear_error = 0\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate)\n","               \n","    #print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    #disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","print(\"inliers:\", inliers / len(images))\n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["num_error: 0.1\n","pixel_error: 0.06939351652645259\n","inliers: 8.651890939779747\n"]}],"source":["error1 = sum(misannotate_errors) / len(misannotate_errors)\n","error2 = sum(pixel_errors) / len(pixel_errors)\n","error3 = inliers / (14720 * epochs)\n","\n","\n","print(\"num_error:\", error1)\n","print(\"pixel_error:\", error2)\n","print(\"inliers:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드(optical flow)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","misannotate_error: 0\n","pixel_error: 0.06245877990587073\n","failed_inliers: 730\n","zero_inliers: 0\n","146810\n"]}],"source":["# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","#원본 이미지를 기준으로 호모그래피 행렬을 구하고, 호모그래피 행렬을 이용하여 특징점의 좌표를 변환하는 코드\n","len_coord = len(origin_coordinate)\n","\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# disappear_errors = []\n","misannotate_errors = []\n","pixel_errors = []\n","\n","failed_inliers = 0\n","zero_inliers = 0\n","\n","inlier_rates = 0\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# 좋은 특징점 찾기 파라미터\n","feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n","\n","epochs = 10\n","\n","count = 0\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(epochs):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        prev_gray = cv2.imread(img0, cv2.IMREAD_GRAYSCALE)\n","        prev_points = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n","        \n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","                \n","                # 첫 프레임에서 특징점 찾기\n","                gray = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n","                next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","                good_old = prev_points[status == 1]\n","                good_new = next_points[status == 1]\n","\n","                if len(good_new) >= 4:\n","                    H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","                        \n","                    if H is not None:\n","                        inliers = CSRansac.calculate_inliers(H, good_old, good_new, 5)\n","                        inlier_rate = inliers / len(good_old)\n","                        if inlier_rate <= 0.3:\n","                            failed_inliers += 1\n","                        inlier_rates += inlier_rate\n","                            \n","                        # 원본 이미지의 좌표를 변환\n","                        points = np.array([[x, y]], dtype='float32')\n","                        projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","                        # 칼만 필터 업데이트\n","                        measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","                        kalman.correct(measured)\n","                        prediction = kalman.predict()\n","                        predicted_points = (prediction[0][0], prediction[1][0])\n","                else:\n","                    failed_inliers += 1       \n","                \n","\n","                projected_pts = tuple(projected_points[0][0])\n","                coord_list[i][j].append(projected_pts)\n","                \n","                prev_gray = gray\n","                prev_points = good_new.reshape(-1, 1, 2)\n","                \n","                count += 1\n","                \n","                \n","    #에러 측정            \n","    # disappear_error = 0\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate, len_coord)\n","               \n","    #print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    #disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)\n","print(count)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["num_error: 0.0\n","pixel_error: 0.06245877990587072\n","inliers: 98.73362610546474\n","failed_inliers: 730\n"]}],"source":["error1 = sum(misannotate_errors) / len(misannotate_errors)\n","error2 = sum(pixel_errors) / len(pixel_errors)\n","error3 = inliers / (14720 * epochs)\n","\n","\n","print(\"num_error:\", error1)\n","print(\"pixel_error:\", error2)\n","print(\"inliers:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드 (SuperPoint + 칼만 필터)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","misannotate_error: 0\n","pixel_error: 0.006548873219875312\n","failed_inliers: 0\n","zero_inliers: 0\n"]}],"source":["# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","\n","# 각종 평가 수치들\n","misannotate_errors = []\n","pixel_errors = []\n","failed_inliers = 0\n","zero_inliers = 0\n","inlier_rates = 0\n","epochs = 10\n","\n","\n","len_coord = len(origin_coordinate)\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(epochs):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        prev_gray = cv2.imread(img0, cv2.IMREAD_GRAYSCALE)\n","        \n","        img0 = load_image(\"img0.png\", grayscale=True)\n","        prev_points = extractor.extract(img0.to(device))\n","        prev_points = prev_points[\"keypoints\"]\n","        prev_points = prev_points.cpu().numpy()\n","        prev_points = prev_points.reshape(-1, 1, 2)\n","        \n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","                \n","                # 첫 프레임에서 특징점 찾기\n","                gray = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n","                next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","                good_old = prev_points[status == 1]\n","                good_new = next_points[status == 1]\n","\n","                if len(good_new) >= 4:\n","                    H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","                        \n","                    if H is not None:\n","                        inliers = mask.ravel().tolist().count(1)\n","                        total_points = len(mask)\n","                        inlier_rate = inliers / total_points\n","                        if inlier_rate <= 0.3:\n","                            failed_inliers += 1\n","                        inlier_rates += inlier_rate\n","                            \n","                        # 원본 이미지의 좌표를 변환\n","                        points = np.array([[x, y]], dtype='float32')\n","                        projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","                        # 칼만 필터 업데이트\n","                        measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","                        kalman.correct(measured)\n","                        prediction = kalman.predict()\n","                        predicted_points = (prediction[0][0], prediction[1][0])\n","                else:\n","                    failed_inliers += 1       \n","                \n","\n","                projected_pts = tuple(projected_points[0][0])\n","                coord_list[i][j].append(projected_pts)\n","                \n","                prev_gray = gray\n","                prev_points = good_new.reshape(-1, 1, 2)\n","                \n","                \n","                \n","    #에러 측정            \n","    # disappear_error = 0\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate, len_coord)\n","               \n","    #print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    #disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["num_error: 0.0\n","pixel_error: 0.006548873219875311\n","inliers: 0.9755523611902226\n"]}],"source":["error1 = sum(misannotate_errors) / len(misannotate_errors)\n","error2 = sum(pixel_errors) / len(pixel_errors)\n","error3 = inlier_rates / (14720 * epochs)\n","\n","\n","print(\"num_error:\", error1)\n","print(\"pixel_error:\", error2)\n","print(\"inliers:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드 (LOFTR + 칼만 필터)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 47\n","pixel_error: 0.7531756358509215\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","misannotate_error: 38\n","pixel_error: 0.4235207252177867\n","failed_inliers: 0\n","zero_inliers: 0\n"]}],"source":["# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","\n","# 각종 평가 수치들\n","misannotate_errors = []\n","pixel_errors = []\n","failed_inliers = 0\n","zero_inliers = 0\n","inlier_rates = 0\n","epochs = 10\n","\n","\n","len_coord = len(origin_coordinate)\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","\n","# LoFTR 모델 초기화\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","loftr = KF.LoFTR(pretrained='outdoor').to(device)\n","\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(epochs):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","        \n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","        prev_gray = cv2.imread(img0, cv2.IMREAD_GRAYSCALE)\n","        \n","        #LOFTR\n","        image = load_and_preprocess_image(img0)\n","\n","        # 특징점 추출\n","        with torch.no_grad():\n","            input_dict = {\"image0\": image, \"image1\": image}\n","            correspondences = loftr(input_dict)\n","\n","        # 특징점 시각화\n","        prev_points = correspondences['keypoints0'].cpu().numpy()\n","        prev_points = prev_points.reshape(-1, 1, 2)\n","        \n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j+1]\n","                \n","                # 첫 프레임에서 특징점 찾기\n","                gray = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n","                next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","                good_old = prev_points[status == 1]\n","                good_new = next_points[status == 1]\n","\n","                if len(good_new) >= 4:\n","                    H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","                        \n","                    if H is not None:\n","                        inliers = mask.ravel().tolist().count(1)\n","                        total_points = len(mask)\n","                        inlier_rate = inliers / total_points\n","                        if inlier_rate <= 0.3:\n","                            failed_inliers += 1\n","                        inlier_rates += inlier_rate\n","                            \n","                        # 원본 이미지의 좌표를 변환\n","                        points = np.array([[x, y]], dtype='float32')\n","                        projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","                        # 칼만 필터 업데이트\n","                        measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","                        kalman.correct(measured)\n","                        prediction = kalman.predict()\n","                        predicted_points = (prediction[0][0], prediction[1][0])\n","                else:\n","                    failed_inliers += 1       \n","                \n","\n","                projected_pts = tuple(projected_points[0][0])\n","                coord_list[i][j].append(projected_pts)\n","                \n","                prev_gray = gray\n","                prev_points = good_new.reshape(-1, 1, 2)\n","                \n","                \n","                \n","    #에러 측정            \n","    # disappear_error = 0\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate, len_coord)\n","               \n","    #print(\"disappear_error:\", disappear_error)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    #disappear_errors.append(disappear_error)\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","    \n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["num_error: 0.0\n","pixel_error: 0.005054367352102526\n","inliers: 0.9765155610255203\n"]}],"source":["error1 = sum(misannotate_errors) / len(misannotate_errors)\n","error2 = sum(pixel_errors) / len(pixel_errors)\n","error3 = inlier_rates / (14720 * epochs)\n","\n","\n","print(\"num_error:\", error1)\n","print(\"pixel_error:\", error2)\n","print(\"inliers:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## 에러 평가 코드 (SuperPoint + Error-state 칼만 필터)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["misannotate_error: 2\n","pixel_error: 0.24357930078563658\n","misannotate_error: 1\n","pixel_error: 0.1213227511855034\n","misannotate_error: 5\n","pixel_error: 0.4789086457135847\n","misannotate_error: 3\n","pixel_error: 0.1717734754122987\n","misannotate_error: 1\n","pixel_error: 0.1032878116856969\n","misannotate_error: 9\n","pixel_error: 0.2702147755087046\n","misannotate_error: 4\n","pixel_error: 0.2527443787925254\n","misannotate_error: 0\n","pixel_error: 0.09177689057066593\n","misannotate_error: 3\n","pixel_error: 0.34295205949171675\n","misannotate_error: 5\n","pixel_error: 0.14040207613571687\n","failed_inliers: 20784\n","zero_inliers: 0\n"]}],"source":["import numpy as np\n","import cv2\n","import time\n","import CSRansac\n","\n","# Error-state Kalman Filter 클래스 정의\n","class ErrorStateKalmanFilter:\n","    def __init__(self):\n","        # 상태 벡터: [x, y, vx, vy]\n","        self.state = np.zeros(4)\n","        # 오차 공분산 행렬\n","        self.P = np.eye(4)\n","        # 프로세스 노이즈 공분산 행렬\n","        self.Q = np.eye(4) * 0.01\n","        # 측정 노이즈 공분산 행렬\n","        self.R = np.eye(2) * 0.1\n","        # 측정 행렬\n","        self.H = np.array([[1, 0, 0, 0],\n","                           [0, 1, 0, 0]])\n","        # 상태 전이 행렬\n","        self.F = np.eye(4)\n","        self.dt = 1.0  # 시간 간격\n","\n","    def predict(self):\n","        # 상태 예측\n","        self.state = self.F @ self.state\n","        # 오차 공분산 예측\n","        self.P = self.F @ self.P @ self.F.T + self.Q\n","\n","    def update(self, measurement):\n","        # 측정 잔차\n","        y = measurement - self.H @ self.state\n","        # 칼만 이득\n","        S = self.H @ self.P @ self.H.T + self.R\n","        K = self.P @ self.H.T @ np.linalg.inv(S)\n","        # 상태 업데이트\n","        self.state = self.state + K @ y\n","        # 오차 공분산 업데이트\n","        I = np.eye(self.P.shape[0])\n","        self.P = (I - K @ self.H) @ self.P\n","\n","    def set_initial_state(self, state):\n","        self.state = state\n","\n","    def set_transition_matrix(self, dt):\n","        self.dt = dt\n","        self.F = np.array([[1, 0, dt, 0],\n","                           [0, 1, 0, dt],\n","                           [0, 0, 1, 0],\n","                           [0, 0, 0, 1]])\n","\n","# Error-state Kalman Filter 초기화\n","kalman = ErrorStateKalmanFilter()\n","initial_state = np.array([0, 0, 0, 0], dtype=np.float32)  # 초기 상태 [x, y, vx, vy]\n","kalman.set_initial_state(initial_state)\n","kalman.set_transition_matrix(1.0)  # 시간 간격 1초로 설정\n","\n","# 각종 평가 수치들\n","misannotate_errors = []\n","pixel_errors = []\n","failed_inliers = 0\n","zero_inliers = 0\n","inlier_rates = 0\n","epochs = 10\n","\n","len_coord = len(origin_coordinate)\n","coord_list = [[] for _i in range(len(origin_coordinate))]\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# 10번 반복하여 측정한 에러를 구함\n","for k in range(epochs):\n","    # 좌표의 개수(동영상의 개수)만큼 반복\n","    for i in range(len_coord):\n","        _images = images[i]\n","        _len_images = len(_images)\n","        x = origin_coordinate[i][0]\n","        y = origin_coordinate[i][1]\n","\n","        # 두 번째 차원의 리스트 초기화\n","        coord_list[i] = [[] for _ in range(_len_images)]\n","\n","        img0 = _images[0]  # 첫 번째 이미지를 target 이미지로 설정\n","        prev_gray = cv2.imread(img0, cv2.IMREAD_GRAYSCALE)\n","\n","        img0 = load_image(\"img0.png\", grayscale=True)\n","        prev_points = extractor.extract(img0.to(device))\n","        prev_points = prev_points[\"keypoints\"]\n","        prev_points = prev_points.cpu().numpy()\n","        prev_points = prev_points.reshape(-1, 1, 2)\n","\n","        for j in range(_len_images):\n","            if j != _len_images - 1:\n","                img1 = _images[j + 1]\n","\n","                # 첫 프레임에서 특징점 찾기\n","                gray = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n","                next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","                good_old = prev_points[status == 1]\n","                good_new = next_points[status == 1]\n","\n","                if len(good_new) >= 4:\n","                    H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","\n","                    if H is not None:\n","                        inliers = mask.ravel().tolist().count(1)\n","                        total_points = len(mask)\n","                        inlier_rate = inliers / total_points\n","                        if inlier_rate <= 0.3:\n","                            failed_inliers += 1\n","                        inlier_rates += inlier_rate\n","\n","                        # 원본 이미지의 좌표를 변환\n","                        points = np.array([[x, y]], dtype='float32')\n","                        projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","\n","                        # Error-state 칼만 필터 업데이트\n","                        measured = np.array([projected_points[0][0][0], projected_points[0][0][1]], dtype=np.float32)\n","                        kalman.predict()\n","                        kalman.update(measured)\n","                        predicted_state = kalman.state\n","                        predicted_points = (predicted_state[0], predicted_state[1])\n","                    else:\n","                        failed_inliers += 1\n","\n","                    projected_pts = tuple(projected_points[0][0])\n","                    coord_list[i][j].append(projected_pts)\n","\n","                prev_gray = gray\n","                prev_points = good_new.reshape(-1, 1, 2)\n","\n","    # 에러 측정\n","    misannotate_error, pixel_error = get_errors(coord_list, float_origin_coordinate, len_coord)\n","    print(\"misannotate_error:\", misannotate_error)\n","    print(\"pixel_error:\", pixel_error)\n","\n","    misannotate_errors.append(misannotate_error)\n","    pixel_errors.append(pixel_error)\n","\n","print(\"failed_inliers:\", failed_inliers)\n","print(\"zero_inliers:\", zero_inliers)\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["num_error: 3.3\n","pixel_error: 0.22169621652820495\n","inliers: 0.3702445652173913\n"]}],"source":["error1 = sum(misannotate_errors) / len(misannotate_errors)\n","error2 = sum(pixel_errors) / len(pixel_errors)\n","error3 = inliers / 14720 * 10\n","\n","\n","print(\"num_error:\", error1)\n","print(\"pixel_error:\", error2)\n","print(\"inliers:\", error3)"]},{"cell_type":"markdown","metadata":{},"source":["## check speed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 테스트용\n","\n","# video_frames 폴더에서 프레임 파일 리스트 가져오기\n","video_frames = os.listdir('video')\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","# 프레임 별 처리 시간 리스트 초기화\n","frame_processing_times = []\n","\n","x = 637 // 2\n","y = 367 // 2\n","image0 = load_image(\"img1.png\", grayscale=True)\n","\n","# 각 프레임 처리\n","for frame in video_frames:\n","    start_time = time.time()\n","    \n","    #image0 = load_image(\"img1.png\", grayscale=True)\n","    feats0 = extractor.extract(image0.to(device))\n","    image1 = load_image_from_path(os.path.join('video', frame), grayscale=True)\n","    feats1 = extractor.extract(image1.to(device))\n","\n","    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n","    feats0, feats1, matches01 = [\n","        rbd(x) for x in [feats0, feats1, matches01]\n","    ]  # remove batch dimension\n","\n","    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n","    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n","\n","    homography, _ = CSRansac.csransac(m_kpts0.cpu().numpy(), m_kpts1.cpu().numpy())\n","    projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","\n","    # 현재 시간 측정\n","    current_time = time.time()\n","\n","    # 프레임 처리 시간 계산\n","    frame_processing_time = current_time - start_time\n","    frame_processing_times.append(frame_processing_time)\n","\n","    # 이전 프레임 처리 시간 업데이트\n","    prev_frame_time = current_time\n","\n","    # FPS 계산\n","    fps = 1.0 / frame_processing_time\n","\n","    # 프레임 수 증가\n","    frame_count += 1\n","\n","    # 이미지 및 매칭 시각화 코드 (생략)\n","\n","# 전체 처리 시간 계산\n","total_processing_time = sum(frame_processing_times)\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 실험 데이터셋 재생 코드"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Frames Processed: 88\n","Average FPS: 21.60\n","Failed Inliers: 0\n","Inlier Rate: 0.9901379728020803\n"]}],"source":["# 광학 추적 방식 + 칼만 필터\n","import cv2\n","import time\n","import CSRansac\n","import numpy as np\n","\n","# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","# 비디오 캡처 객체 초기화\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","# 예시 좌표\n","x, y = 637 / 2, 367 / 2  \n","points = np.array([[x, y]], dtype='float32')\n","\n","# 원본 이미지와 투영할 좌표\n","origin_image = cv2.imread('img0.png')\n","prev_gray = cv2.cvtColor(origin_image, cv2.COLOR_BGR2GRAY)\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# 좋은 특징점 찾기 파라미터\n","feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n","\n","# 첫 프레임에서 특징점 찾기\n","# prev_points = (cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params))\n","img0 = load_image(\"img0.png\", grayscale=True)\n","prev_points = extractor.extract(img0.to(device))\n","prev_points = prev_points[\"keypoints\"]\n","prev_points = prev_points.cpu().numpy()\n","prev_points = prev_points.reshape(-1, 1, 2)\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","failed_inliers_count = 0\n","inlier_rates=0\n","# 프레임 별 처리 시간 리스트 초기화\n","total_processing_time = 0\n","\n","first = 0\n","\n","start_time = time.time()\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    if first == 0:\n","        first = 1\n","        continue\n","    \n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","    good_old = prev_points[status == 1]\n","    good_new = next_points[status == 1]\n","    \n","    if len(good_new) >= 4:\n","        H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","        if H is not None:\n","            inliers = mask.ravel().tolist().count(1)\n","            total_points = len(mask)\n","            inlier_rate = inliers / total_points\n","            if inlier_rate <= 0.3:\n","                failed_inliers += 1\n","            inlier_rates += inlier_rate\n","            \n","            # 원본 이미지의 좌표를 변환\n","            projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","            # 칼만 필터 업데이트\n","            measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","            kalman.correct(measured)\n","            prediction = kalman.predict()\n","            predicted_points = (prediction[0][0], prediction[1][0])\n","            # 결과 표시\n","            cv2.circle(frame, (int(predicted_points[0]), int(predicted_points[1])), 5, (0, 0, 255), -1)\n","    \n","    prev_gray = gray\n","    prev_points = good_new.reshape(-1, 1, 2)\n","    \n","    # 프레임 수 증가\n","    frame_count += 1\n","    \n","    cv2.imshow('frame', frame)\n","    if cv2.waitKey(30) & 0xFF == 27:\n","        break\n","\n","\n","# 현재 프레임 처리 시간 측정\n","end_time = time.time()\n","frame_processing_time = end_time - start_time\n","total_processing_time += frame_processing_time\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")\n","print(f\"Failed Inliers: {failed_inliers_count}\")\n","print(f\"Inlier Rate: {inlier_rates / frame_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 기존 추출 알고리즘 + 칼만 필터\n","import cv2\n","import time\n","import CSRansac\n","import numpy as np\n","\n","# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","failed_inliers = 0\n","    \n","# 좌표의 개수(동영상의 개수)만큼 반복\n","for i in range(1):\n","    _images = images[0]\n","    _len_images = len(_images)\n","    x = origin_coordinate[0][0]\n","    y = origin_coordinate[0][1]\n","\n","    img0 = _images[0] # 첫 번째 이미지를 target 이미지로 설정\n","    for j in range(_len_images):\n","        if j == 0:\n","            continue\n","        \n","        img1 = _images[j]\n","        _img1 = cv2.imread(img1)\n","\n","        # LightGlue\n","        results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n","        target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n","        frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n","\n","        homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n","        if mask < 0.3:\n","            failed_inliers += 1\n","            cv2.imshow('frame', _img1)\n","            img0 = img1\n","            continue\n","        \n","        projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n","        measured = np.array([[projected_pts[0][0][0], projected_pts[0][0][1], 0, 0]], dtype=np.float32).T\n","        kalman.correct(measured)\n","        prediction = kalman.predict()\n","        predicted_points = (prediction[0][0], prediction[1][0])\n","        \n","        img0 = img1\n","        \n","        cv2.circle(_img1, (int(predicted_points[0]), int(predicted_points[1])), 15, (0, 0, 255), -1)\n","        cv2.circle(_img1, (int(predicted_points[0]), int(predicted_points[1])), 3, (0, 0, 0), -1)\n","        cv2.imshow('frame', _img1)\n","        \n","        key = cv2.waitKey(5)\n","        if key == 27:\n","            break\n","    break\n","            \n","cv2.destroyAllWindows()\n","print(\"failed_inliers:\", failed_inliers)\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","# 비디오 캡처 객체 초기화\n","cap = cv2.VideoCapture('video.mp4')\n","\n","# 원본 이미지와 투영할 좌표\n","origin_image = cv2.imread('origin.png')\n","x, y = 100, 150  # 예시 좌표\n","points = np.array([[x, y]], dtype='float32')\n","\n","# 첫 프레임 읽기\n","ret, prev_frame = cap.read()\n","prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# 좋은 특징점 찾기 파라미터\n","feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n","\n","# 첫 프레임에서 특징점 찾기\n","prev_points = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","    good_old = prev_points[status == 1]\n","    good_new = next_points[status == 1]\n","    \n","    if len(good_new) >= 4:\n","        H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","        if H is not None:\n","            # 원본 이미지의 좌표를 변환\n","            projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","            # 칼만 필터 업데이트\n","            measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","            kalman.correct(measured)\n","            prediction = kalman.predict()\n","            predicted_points = (prediction[0][0], prediction[1][0])\n","            # 결과 표시\n","            cv2.circle(frame, (int(predicted_points[0]), int(predicted_points[1])), 5, (0, 0, 255), -1)\n","    \n","    prev_gray = gray.copy()\n","    prev_points = good_new.reshape(-1, 1, 2)\n","    \n","    cv2.imshow('frame', frame)\n","    if cv2.waitKey(30) & 0xFF == 27:\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 1848, 2)\n","(1848, 1, 2)\n"]}],"source":["# loftr + 광학 추적 방식 + 칼만 필터\n","import cv2\n","import time\n","import numpy as np\n","\n","# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","# 비디오 캡처 객체 초기화\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","# 예시 좌표\n","x, y = 637 / 2, 367 / 2  \n","points = np.array([[x, y]], dtype='float32')\n","\n","# 원본 이미지와 투영할 좌표\n","origin_image = cv2.imread('img0.png')\n","prev_gray = cv2.cvtColor(origin_image, cv2.COLOR_BGR2GRAY)\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# 좋은 특징점 찾기 파라미터\n","feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n","\n","# 첫 프레임에서 특징점 찾기\n","# prev_points = (cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params))\n","img0 = load_image(\"img0.png\", grayscale=True)\n","prev_points = extractor.extract(img0.to(device))\n","prev_points = prev_points[\"keypoints\"]\n","prev_points = prev_points.cpu().numpy()\n","prev_points = prev_points.reshape(-1, 1, 2)\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","failed_inliers_count = 0\n","inlier_rates=0\n","# 프레임 별 처리 시간 리스트 초기화\n","total_processing_time = 0\n","\n","first = 0\n","\n","start_time = time.time()\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    if first == 0:\n","        first = 1\n","        continue\n","    \n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","    good_old = prev_points[status == 1]\n","    good_new = next_points[status == 1]\n","    \n","    if len(good_new) >= 4:\n","        H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","        if H is not None:\n","            inliers = mask.ravel().tolist().count(1)\n","            total_points = len(mask)\n","            inlier_rate = inliers / total_points\n","            if inlier_rate <= 0.3:\n","                failed_inliers += 1\n","            inlier_rates += inlier_rate\n","            \n","            # 원본 이미지의 좌표를 변환\n","            projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","            # 칼만 필터 업데이트\n","            measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","            kalman.correct(measured)\n","            prediction = kalman.predict()\n","            predicted_points = (prediction[0][0], prediction[1][0])\n","            # 결과 표시\n","            cv2.circle(frame, (int(predicted_points[0]), int(predicted_points[1])), 5, (0, 0, 255), -1)\n","    \n","    prev_gray = gray\n","    prev_points = good_new.reshape(-1, 1, 2)\n","    \n","    # 프레임 수 증가\n","    frame_count += 1\n","    \n","    cv2.imshow('frame', frame)\n","    if cv2.waitKey(30) & 0xFF == 27:\n","        break\n","\n","\n","# 현재 프레임 처리 시간 측정\n","end_time = time.time()\n","frame_processing_time = end_time - start_time\n","total_processing_time += frame_processing_time\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")\n","print(f\"Failed Inliers: {failed_inliers_count}\")\n","print(f\"Inlier Rate: {inlier_rates / frame_count}\")"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Frames Processed: 367\n","Average FPS: 21.83\n","Failed Inliers: 0\n","Inlier Rate: 0.9891542005668806\n"]}],"source":["# loftr + 광학 추적 방식 + 칼만 필터\n","import cv2\n","import time\n","import numpy as np\n","import torch\n","import kornia as K\n","import kornia.feature as KF\n","\n","# LoFTR 모델 초기화\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","loftr = KF.LoFTR(pretrained='outdoor').to(device)\n","\n","image_path = 'img0.png'\n","image = load_and_preprocess_image(image_path)\n","\n","# 특징점 추출\n","with torch.no_grad():\n","    input_dict = {\"image0\": image, \"image1\": image}\n","    correspondences = loftr(input_dict)\n","\n","# 특징점 시각화\n","prev_points = correspondences['keypoints0'].cpu().numpy()\n","prev_points = prev_points.reshape(-1, 1, 2)\n","\n","\n","# 칼만 필터 초기화\n","kalman = cv2.KalmanFilter(8, 4)\n","kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n","kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n","kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n","kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n","kalman.errorCovPost = np.eye(8, dtype=np.float32)\n","\n","# 비디오 캡처 객체 초기화\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","\n","# 예시 좌표\n","x, y = 637 / 2, 367 / 2  \n","points = np.array([[x, y]], dtype='float32')\n","\n","# 원본 이미지와 투영할 좌표\n","origin_image = cv2.imread('img0.png')\n","prev_gray = cv2.cvtColor(origin_image, cv2.COLOR_BGR2GRAY)\n","\n","# Lucas-Kanade optical flow 파라미터\n","lk_params = dict(winSize=(15, 15), maxLevel=2,\n","                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# # 좋은 특징점 찾기 파라미터\n","# feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n","\n","# 첫 프레임에서 특징점 찾기\n","# prev_points = (cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params))\n","# img0 = load_image(\"img0.png\", grayscale=True)\n","# prev_points = extractor.extract(img0.to(device))\n","# prev_points = prev_points[\"keypoints\"]\n","# prev_points = prev_points.cpu().numpy()\n","# prev_points = prev_points.reshape(-1, 1, 2)\n","\n","# 프레임 수 초기화\n","frame_count = 0\n","\n","failed_inliers_count = 0\n","inlier_rates=0\n","# 프레임 별 처리 시간 리스트 초기화\n","total_processing_time = 0\n","\n","first = 0\n","\n","start_time = time.time()\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    \n","    if first == 0:\n","        first = 1\n","        continue\n","    \n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n","    good_old = prev_points[status == 1]\n","    good_new = next_points[status == 1]\n","    \n","    if len(good_new) >= 4:\n","        H, mask = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n","        if H is not None:\n","            inliers = mask.ravel().tolist().count(1)\n","            total_points = len(mask)\n","            inlier_rate = inliers / total_points\n","            if inlier_rate <= 0.3:\n","                failed_inliers += 1\n","            inlier_rates += inlier_rate\n","            \n","            # 원본 이미지의 좌표를 변환\n","            projected_points = cv2.perspectiveTransform(np.array([points]), H)\n","            # 칼만 필터 업데이트\n","            measured = np.array([[projected_points[0][0][0], projected_points[0][0][1], 0, 0]], dtype=np.float32).T\n","            kalman.correct(measured)\n","            prediction = kalman.predict()\n","            predicted_points = (prediction[0][0], prediction[1][0])\n","            # 결과 표시\n","            cv2.circle(frame, (int(predicted_points[0]), int(predicted_points[1])), 5, (0, 0, 255), -1)\n","    \n","    prev_gray = gray\n","    prev_points = good_new.reshape(-1, 1, 2)\n","    \n","    # 프레임 수 증가\n","    frame_count += 1\n","    \n","    cv2.imshow('frame', frame)\n","    if cv2.waitKey(30) & 0xFF == 27:\n","        break\n","\n","\n","# 현재 프레임 처리 시간 측정a\n","end_time = time.time()\n","frame_processing_time = end_time - start_time\n","total_processing_time += frame_processing_time\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","\n","# 전체 프레임 수와 전체 처리 시간을 사용하여 평균 FPS 계산\n","average_fps = frame_count / total_processing_time\n","\n","print(f\"Total Frames Processed: {frame_count}\")\n","print(f\"Average FPS: {average_fps:.2f}\")\n","print(f\"Failed Inliers: {failed_inliers_count}\")\n","print(f\"Inlier Rate: {inlier_rates / frame_count}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 광학 추적 시각화 코드"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# optical flow 추적\n","\n","import cv2\n","import numpy as np\n","\n","cap = cv2.VideoCapture('demo_video_resized.mp4')\n","fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n","delay = int(1000/fps)\n","# 추적 경로를 그리기 위한 랜덤 색상\n","color = np.random.randint(0,255,(200,3))\n","lines = None  #추적 선을 그릴 이미지 저장 변수\n","prevImg = None  # 이전 프레임 저장 변수\n","# calcOpticalFlowPyrLK 중지 요건 설정\n","termcriteria =  (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n","\n","is_paused = False  # 일시정지 상태를 나타내는 변수\n","\n","while cap.isOpened():\n","    if not is_paused:\n","        ret,frame = cap.read()\n","        if not ret:\n","            break\n","\n","        img_draw = frame.copy()\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        # 최초 프레임 경우\n","        if prevImg is None:\n","            prevImg = gray\n","            # 추적선 그릴 이미지를 프레임 크기에 맞게 생성\n","            lines = np.zeros_like(frame)\n","            # 추적 시작을 위한 코너 검출  ---①\n","            prevPt = cv2.goodFeaturesToTrack(prevImg, 200, 0.01, 10)\n","        else:\n","            nextImg = gray\n","            # 옵티컬 플로우로 다음 프레임의 코너점  찾기 ---②\n","            nextPt, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, \\\n","                                            prevPt, None, criteria=termcriteria)\n","            # 대응점이 있는 코너, 움직인 코너 선별 ---③\n","            prevMv = prevPt[status==1]\n","            nextMv = nextPt[status==1]\n","            for i,(p, n) in enumerate(zip(prevMv, nextMv)):\n","                px,py = p.ravel()\n","                nx,ny = n.ravel()\n","                # 이전 코너와 새로운 코너에 선그리기 ---④\n","                cv2.line(lines, (int(px), int(py)), (int(nx), int(ny)), color[i].tolist(), 2)\n","                # 새로운 코너에 점 그리기\n","                cv2.circle(img_draw, (int(nx), int(ny)), 2, color[i].tolist(), -1)\n","            # 누적된 추적 선을 출력 이미지에 합성 ---⑤\n","            img_draw = cv2.add(img_draw, lines)\n","            # 다음 프레임을 위한 프레임과 코너점 이월\n","            prevImg = nextImg\n","            prevPt = nextMv.reshape(-1,1,2)\n","\n","        cv2.imshow('OpticalFlow-LK', img_draw)\n","        key = cv2.waitKey(delay)\n","        if key == 27 : # Esc:종료\n","            break\n","        elif key == 8: # Backspace:추적 이력 지우기\n","            prevImg = None\n","        elif key == 32:  # Space: 일시정지/재생 토글\n","            is_paused = not is_paused\n","        \n","cv2.destroyAllWindows()\n","cap.release()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","class ErrorStateKalmanFilter:\n","    def __init__(self):\n","        # 상태 벡터: [x, y, vx, vy]\n","        self.state = np.zeros(4)\n","        # 오차 공분산 행렬\n","        self.P = np.eye(4)\n","        # 프로세스 노이즈 공분산 행렬\n","        self.Q = np.eye(4) * 0.01\n","        # 측정 노이즈 공분산 행렬\n","        self.R = np.eye(2) * 0.1\n","        # 측정 행렬\n","        self.H = np.array([[1, 0, 0, 0],\n","                           [0, 1, 0, 0]])\n","        # 상태 전이 행렬\n","        self.F = np.eye(4)\n","        self.dt = 1.0  # 시간 간격\n","\n","    def predict(self):\n","        # 상태 예측\n","        self.state = self.F @ self.state\n","        # 오차 공분산 예측\n","        self.P = self.F @ self.P @ self.F.T + self.Q\n","\n","    def update(self, measurement):\n","        # 측정 잔차\n","        y = measurement - self.H @ self.state\n","        # 칼만 이득\n","        S = self.H @ self.P @ self.H.T + self.R\n","        K = self.P @ self.H.T @ np.linalg.inv(S)\n","        # 상태 업데이트\n","        self.state = self.state + K @ y\n","        # 오차 공분산 업데이트\n","        I = np.eye(self.P.shape[0])\n","        self.P = (I - K @ self.H) @ self.P\n","\n","    def set_initial_state(self, state):\n","        self.state = state\n","\n","    def set_transition_matrix(self, dt):\n","        self.dt = dt\n","        self.F = np.array([[1, 0, dt, 0],\n","                           [0, 1, 0, dt],\n","                           [0, 0, 1, 0],\n","                           [0, 0, 0, 1]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# 예제 데이터 생성\n","true_state = np.array([0, 0, 1, 1])  # 초기 상태 [x, y, vx, vy]\n","measurements = []\n","true_positions = []\n","predicted_positions = []\n","\n","kf = ErrorStateKalmanFilter()\n","kf.set_initial_state(true_state)\n","kf.set_transition_matrix(1.0)\n","\n","for t in range(50):\n","    # 실제 상태 갱신\n","    true_state = kf.F @ true_state\n","    true_positions.append(true_state[:2])\n","\n","    # 측정값 생성 (노이즈 추가)\n","    measurement = true_state[:2] + np.random.multivariate_normal([0, 0], kf.R)\n","    measurements.append(measurement)\n","\n","    # 칼만 필터 예측 및 업데이트\n","    kf.predict()\n","    kf.update(measurement)\n","    predicted_positions.append(kf.state[:2])\n","\n","# 결과 시각화\n","true_positions = np.array(true_positions)\n","measurements = np.array(measurements)\n","predicted_positions = np.array(predicted_positions)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
>>>>>>> Stashed changes
