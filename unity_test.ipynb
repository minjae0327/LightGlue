{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import load_image, rbd, load_image_from_path\n",
    "import CSRansac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(device)\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "#matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).eval().to(device)\n",
    "#matcher.compile(mode='reduce-overhead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lightglue(img0, img1):\n",
    "    img0 = load_image(img0)\n",
    "    img1 = load_image(img1)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    \n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "    \n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "        \n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (640, 480))  # 필요한 경우 이미지 크기 조정\n",
    "    image = K.image_to_tensor(image, False).float() / 255.0\n",
    "    image = image.to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_keypoints(target_img, video_img):\n",
    "    # 이미지를 불러옴\n",
    "    img0 = load_image(target_img, grayscale=True)\n",
    "    img1 = load_image(video_img , grayscale=True)\n",
    "\n",
    "    # extract local features\n",
    "    feats0 = extractor.extract(img0.to(device))  # auto-resize the image, disable with resize=None\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "\n",
    "    # match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "\n",
    "    # get results\n",
    "    kpts0 = feats0[\"keypoints\"]\n",
    "    kpts1 = feats1[\"keypoints\"]\n",
    "    matches = matches01['matches']  # indices with shape (K,2)\n",
    "    points0 = kpts0[matches[..., 0]]  # coordinates in img0, shape (K,2)\n",
    "    points1 = kpts1[matches[..., 1]]  # coordinates in img1, shape (K,2)\n",
    "\n",
    "    return {\n",
    "        \"points0\": points0,\n",
    "        \"points1\": points1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(coord_list, float_origin_coordinate, len_coord, len_videos):\n",
    "    misannotate_error = 0\n",
    "    pixel_error = 0\n",
    "    \n",
    "    for index in range(len_videos):\n",
    "        for i in range(len_coord):\n",
    "            try:\n",
    "                origin_x = float_origin_coordinate[index][i][0]\n",
    "                origin_y = float_origin_coordinate[index][i][1]\n",
    "                \n",
    "                _coord = coord_list[index][i]\n",
    "                \n",
    "                x = _coord[0][0]\n",
    "                y = _coord[0][1]\n",
    "                \n",
    "                x = x / 640\n",
    "                y = y / 480\n",
    "                \n",
    "                x = round(x, 4)\n",
    "                y = round(y, 4)\n",
    "                \n",
    "                distance = math.sqrt((origin_x - x)**2 + (origin_y - y)**2)\n",
    "                \n",
    "                if distance > 0.1:\n",
    "                    misannotate_error += 1\n",
    "                \n",
    "                if distance > pixel_error:\n",
    "                    pixel_error = distance\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    return misannotate_error, pixel_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VideoWriter 초기화\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "# out = cv2.VideoWriter('unity_annotated_lightglue.mp4', fourcc, 30, (640, 480))\n",
    "\n",
    "# # 마우스 클릭 이벤트 핸들러\n",
    "# clicked_coords = []\n",
    "\n",
    "# def mouse_callback(event, x, y, flags, param):\n",
    "#     global clicked_coords\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         clicked_coords = [x, y]\n",
    "\n",
    "# # 웹캠 초기화\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"웹캠을 열 수 없습니다.\")\n",
    "#     exit()\n",
    "\n",
    "# cv2.namedWindow('Webcam')\n",
    "# cv2.setMouseCallback('Webcam', mouse_callback)\n",
    "\n",
    "# frame_count = 0\n",
    "# total_time = 0\n",
    "# coords_set = False\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         print(\"프레임을 읽을 수 없습니다.\")\n",
    "#         break\n",
    "    \n",
    "#     cv2.imshow('Webcam', frame)\n",
    "    \n",
    "#     if len(clicked_coords) == 2 and not coords_set:\n",
    "#         x, y = clicked_coords\n",
    "#         coords_set = True\n",
    "#         print(f\"클릭된 좌표: ({x}, {y})\")\n",
    "    \n",
    "#     key = cv2.waitKey(1)\n",
    "#     if key == 27:  # ESC 키\n",
    "#         break\n",
    "    \n",
    "#     if coords_set:\n",
    "#         img0 = frame  # 첫 프레임을 target image로 사용\n",
    "#         break\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # 각 프레임 처리\n",
    "# while True:\n",
    "#     ret, img1 = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     results_lightglue = matching_keypoints(img0, img1, stabilizing=False)\n",
    "#     target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n",
    "#     frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n",
    "\n",
    "#     homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n",
    "#     projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "    \n",
    "#     # 결과를 비디오에 기록\n",
    "#     out.write(img1)\n",
    "    \n",
    "#     img0 = img1\n",
    "    \n",
    "#     frame_count += 1\n",
    "\n",
    "#     cv2.imshow('Webcam', img1)\n",
    "#     key = cv2.waitKey(1)\n",
    "#     if key == 27:  # ESC 키\n",
    "#         break\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# total_time += end_time - start_time   \n",
    "# average_time = frame_count / total_time\n",
    "# print(\"FPS : \", average_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클릭된 좌표: (317, 175)\n",
      "클릭된 좌표: (289, 233)\n",
      "클릭된 좌표: (399, 148)\n"
     ]
    }
   ],
   "source": [
    "# VideoWriter 초기화\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('unity_annotated_lightglue.mp4', fourcc, 30, (640, 480))\n",
    "\n",
    "video_path = \"demo_video.mp4\"\n",
    "\n",
    "# 마우스 클릭 이벤트 핸들러\n",
    "clicked_coords = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global clicked_coords\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        clicked_coords.append((x, y))\n",
    "        print(f\"클릭된 좌표: ({x}, {y})\")\n",
    "\n",
    "frame_count = 0\n",
    "total_time = 0\n",
    "paused = True\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"비디오를 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 첫 프레임을 target image로 사용\n",
    "ret, img0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"첫 번째 프레임을 읽을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "img0 = cv2.resize(img0, (640, 480))\n",
    "cv2.namedWindow('frame')\n",
    "cv2.setMouseCallback('frame', mouse_callback)\n",
    "\n",
    "cv2.imshow('frame', img0)\n",
    "\n",
    "# 일시 정지 상태에서 사용자가 마우스로 클릭하여 어노테이션할 좌표를 얻음\n",
    "while paused:\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 32:  # 스페이스바를 누르면 재생 시작\n",
    "        paused = False\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# 각 프레임 처리\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, img1 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img1 = cv2.resize(img1, (640, 480))\n",
    "        frame = img1.copy()\n",
    "        \n",
    "        # LightGlue\n",
    "        results_lightglue = matching_keypoints(img0, img1)\n",
    "        target_keypoint = results_lightglue[\"points0\"].cpu().numpy()\n",
    "        frame_keypoint = results_lightglue[\"points1\"].cpu().numpy()\n",
    "\n",
    "        homography, mask = CSRansac.csransac(target_keypoint, frame_keypoint)\n",
    "\n",
    "        # 각 클릭된 좌표를 변환하여 표시\n",
    "        for x, y in clicked_coords:\n",
    "            projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "            # clicked_coords[i] = projected_pts\n",
    "            x = int(projected_pts[0])\n",
    "            y = int(projected_pts[1])\n",
    "            \n",
    "            cv2.circle(frame, (x, y), 15, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 0, 0), -1)    \n",
    "        \n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # img0 = img1\n",
    "        # frame_count += 1\n",
    "\n",
    "        key = cv2.waitKey(5)\n",
    "        if key == 27:  # ESC 키를 누르면 종료\n",
    "            break\n",
    "        elif key == 32:  # 스페이스바를 누르면 일시 정지\n",
    "            paused = True\n",
    "    else:\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 32:  # 스페이스바를 누르면 재생 시작\n",
    "            paused = False\n",
    "        elif key == 27:  # ESC 키를 누르면 종료\n",
    "            break\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# total_time += end_time - start_time   \n",
    "# average_time = frame_count / total_time\n",
    "# print(\"FPS : \", average_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VideoWriter 초기화\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('unity_annotated_lightglue.mp4', fourcc, 30, (640, 480))\n",
    "\n",
    "video_path = \"demo_video.mp4\"\n",
    "\n",
    "# 칼만 필터 초기화\n",
    "kalman = cv2.KalmanFilter(8, 4)\n",
    "kalman.measurementMatrix = np.eye(4, 8, dtype=np.float32)\n",
    "kalman.transitionMatrix = np.eye(8, dtype=np.float32)\n",
    "kalman.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01\n",
    "kalman.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1\n",
    "kalman.errorCovPost = np.eye(8, dtype=np.float32)\n",
    "\n",
    "# LoFTR 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loftr = KF.LoFTR(pretrained='outdoor').to(device)\n",
    "\n",
    "# Lucas-Kanade optical flow 파라미터\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "# 마우스 클릭 이벤트 핸들러\n",
    "clicked_coords = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global clicked_coords\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        clicked_coords.append((x, y))\n",
    "        print(f\"클릭된 좌표: ({x}, {y})\")\n",
    "\n",
    "frame_count = 0\n",
    "total_time = 0\n",
    "paused = True\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"비디오를 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 첫 프레임을 target image로 사용\n",
    "ret, img0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"첫 번째 프레임을 읽을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "img0 = cv2.resize(img0, (640, 480))\n",
    "cv2.namedWindow('frame')\n",
    "cv2.setMouseCallback('frame', mouse_callback)\n",
    "\n",
    "cv2.imshow('frame', img0)\n",
    "\n",
    "prev_gray = cv2.imread(img0, cv2.IMREAD_GRAYSCALE)\n",
    "prev_gray = cv2.resize(prev_gray, (640, 480))\n",
    "\n",
    "# LOFTR\n",
    "image = load_and_preprocess_image(img0)\n",
    "\n",
    "# 특징점 추출\n",
    "with torch.no_grad():\n",
    "    input_dict = {\"image0\": image, \"image1\": image}\n",
    "    correspondences = loftr(input_dict)\n",
    "\n",
    "prev_points = correspondences['keypoints0'].cpu().numpy()\n",
    "prev_points = prev_points.reshape(-1, 1, 2)\n",
    "\n",
    "# 일시 정지 상태에서 사용자가 마우스로 클릭하여 어노테이션할 좌표를 얻음\n",
    "while paused:\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 32:  # 스페이스바를 누르면 재생 시작\n",
    "        paused = False\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# 각 프레임 처리\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, img1 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img1 = cv2.resize(img1, (640, 480))\n",
    "        frame = img1.copy()\n",
    "        \n",
    "        _frame = cv2.imread(img1)\n",
    "        gray = cv2.cvtColor(_frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray, (640, 480))\n",
    "        next_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n",
    "        good_old = prev_points[status == 1]\n",
    "        good_new = next_points[status == 1]\n",
    "\n",
    "        H, _ = cv2.findHomography(good_old, good_new, cv2.RANSAC, 5.0)\n",
    "\n",
    "        # 각 클릭된 좌표를 변환하여 표시\n",
    "        for x, y in clicked_coords:\n",
    "            projected_pts = CSRansac.perspective_transform(np.array([x, y]), homography)\n",
    "            # clicked_coords[i] = projected_pts\n",
    "            x = int(projected_pts[0])\n",
    "            y = int(projected_pts[1])\n",
    "            \n",
    "            cv2.circle(frame, (x, y), 15, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 0, 0), -1)    \n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # img0 = img1\n",
    "        # frame_count += 1\n",
    "\n",
    "        key = cv2.waitKey(5)\n",
    "        if key == 27:  # ESC 키를 누르면 종료\n",
    "            break\n",
    "        elif key == 32:  # 스페이스바를 누르면 일시 정지\n",
    "            paused = True\n",
    "    else:\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 32:  # 스페이스바를 누르면 재생 시작\n",
    "            paused = False\n",
    "        elif key == 27:  # ESC 키를 누르면 종료\n",
    "            break\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# total_time += end_time - start_time   \n",
    "# average_time = frame_count / total_time\n",
    "# print(\"FPS : \", average_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
